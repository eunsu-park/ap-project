# Solar Wind Prediction - Multimodal Deep Learning

íƒœì–‘í’ ì˜ˆì¸¡ì„ ìœ„í•œ ë©€í‹°ëª¨ë‹¬ ë”¥ëŸ¬ë‹ ëª¨ë¸ì…ë‹ˆë‹¤. Transformer (ì‹œê³„ì—´ ë°ì´í„°)ì™€ ConvLSTM (ìœ„ì„± ì´ë¯¸ì§€)ì„ ê²°í•©í•˜ì—¬ ì§€êµ¬ ìê¸°ê¶Œ êµë€ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” íŠ¹ì§•

### ëª¨ë¸ ì•„í‚¤í…ì²˜
- **Transformer**: OMNI íƒœì–‘í’ ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬
- **ConvLSTM**: SDO ìœ„ì„± ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ì²˜ë¦¬
- **Cross-Modal Fusion**: ë‘ ëª¨ë‹¬ë¦¬í‹° ì •ë³´ í†µí•©
- **Contrastive Learning**: ë©€í‹°ëª¨ë‹¬ íŠ¹ì„± ì •ë ¬

### ì½”ë“œ í’ˆì§ˆ
- âœ… **ëª¨ë“ˆí™”**: ëª…í™•í•œ ì±…ì„ ë¶„ë¦¬ (Trainer, Validator, DataProcessor ë“±)
- âœ… **ì¬í˜„ì„±**: ì™„ì „í•œ ì‹œë“œ ì œì–´ ë° ê²°ì •ì  ì•Œê³ ë¦¬ì¦˜
- âœ… **íš¨ìœ¨ì„±**: ë©”ëª¨ë¦¬ ìµœì í™” ë° DataLoader ìµœì í™”
- âœ… **í™•ì¥ì„±**: ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ ìš©ì´

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
project/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ local_dev.yaml        # ì„¤ì • íŒŒì¼
â”‚
â”œâ”€â”€ Core Components
â”‚   â”œâ”€â”€ pipeline.py           # ë°ì´í„° íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ losses.py             # Loss í•¨ìˆ˜ë“¤
â”‚   â”œâ”€â”€ trainers.py           # í•™ìŠµ ë¡œì§
â”‚   â””â”€â”€ validators.py         # ê²€ì¦ ë¡œì§
â”‚
â”œâ”€â”€ Scripts
â”‚   â”œâ”€â”€ train.py              # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ validation.py         # ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
â”‚
â”œâ”€â”€ Model & Utilities
â”‚   â”œâ”€â”€ networks.py           # ëª¨ë¸ ì •ì˜
â”‚   â””â”€â”€ utils.py              # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”‚
â””â”€â”€ Documentation
    â”œâ”€â”€ README.md             # ì´ íŒŒì¼
    â””â”€â”€ CONFIG_GUIDE.md       # ì„¤ì • ê°€ì´ë“œ (ì„ íƒ)
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install torch torchvision
pip install numpy pandas h5py
pip install hydra-core matplotlib

# ë˜ëŠ” requirements.txt ì‚¬ìš©
pip install -r requirements.txt
```

### 2. ì„¤ì • íŒŒì¼ ì¤€ë¹„

`configs/local_dev.yaml` íŒŒì¼ì—ì„œ ê²½ë¡œë¥¼ ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •:

```yaml
environment:
  data_root: '/YOUR/PATH/TO/datasets'      # ë°ì´í„°ì…‹ ê²½ë¡œ
  save_root: '/YOUR/PATH/TO/results'       # ê²°ê³¼ ì €ì¥ ê²½ë¡œ

validation:
  checkpoint_path: /YOUR/PATH/TO/model.pth # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
  output_dir: /YOUR/PATH/TO/output         # ê²€ì¦ ê²°ê³¼ ê²½ë¡œ
```

### 3. í•™ìŠµ

```bash
python train.py --config-name=local_dev
```

### 4. ê²€ì¦

```bash
python validation.py --config-name=local_dev
```

## ğŸ“š ì£¼ìš” ì»´í¬ë„ŒíŠ¸

### 1. pipeline.py - ë°ì´í„° íŒŒì´í”„ë¼ì¸

**ì£¼ìš” í´ë˜ìŠ¤:**

```python
Normalizer                  # SDO/OMNI ë°ì´í„° ì •ê·œí™”
OnlineStatistics           # ë©”ëª¨ë¦¬ íš¨ìœ¨ì  í†µê³„ ê³„ì‚°
SamplingStrategy           # Under/Oversampling ì „ëµ
HDF5Reader                 # HDF5 íŒŒì¼ ì½ê¸°
DataProcessor              # ë°ì´í„° ì „ì²˜ë¦¬
MultimodalDataset          # PyTorch Dataset
```

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from pipeline import create_dataloader

dataloader = create_dataloader(config, logger)
for batch in dataloader:
    sdo = batch['sdo']          # (B, C, T, H, W)
    inputs = batch['inputs']     # (B, T, C)
    targets = batch['targets']   # (B, T, C)
    labels = batch['labels']     # (B, 1, 1)
```

### 2. losses.py - Loss í•¨ìˆ˜

**ì£¼ìš” í´ë˜ìŠ¤:**

```python
MultiModalContrastiveLoss   # InfoNCE contrastive loss
MultiModalMSELoss          # MSE consistency loss
create_loss_functions()    # Configì—ì„œ loss ìƒì„±
```

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from losses import create_loss_functions

reg_criterion, cont_criterion = create_loss_functions(config)

# í•™ìŠµ ì‹œ
reg_loss = reg_criterion(outputs, targets)
cont_loss = cont_criterion(transformer_features, convlstm_features)
total_loss = reg_loss + lambda_contrastive * cont_loss
```

### 3. trainers.py - í•™ìŠµ ê´€ë¦¬

**ì£¼ìš” í´ë˜ìŠ¤:**

```python
MetricsTracker             # í•™ìŠµ metrics ìë™ ì¶”ì 
CheckpointManager          # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬
Trainer                    # ì „ì²´ í•™ìŠµ ë£¨í”„ ê´€ë¦¬
```

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from trainers import Trainer

trainer = Trainer(
    config, model, optimizer, scheduler,
    criterion, contrastive_criterion,
    device, logger
)

history = trainer.fit(dataloader, num_epochs=10)
```

### 4. validators.py - ê²€ì¦ ê´€ë¦¬

**ì£¼ìš” í´ë˜ìŠ¤:**

```python
MetricsAggregator          # ê²€ì¦ metrics ì§‘ê³„
ResultsWriter              # ê²°ê³¼ íŒŒì¼ ì €ì¥
Validator                  # ì „ì²´ ê²€ì¦ ë£¨í”„ ê´€ë¦¬
```

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from validators import Validator

validator = Validator(config, model, criterion, device, logger)
results = validator.validate(dataloader)
```

## âš™ï¸ ì„¤ì • ê°€ì´ë“œ

### í•„ìˆ˜ ê²½ë¡œ ì„¤ì •

```yaml
environment:
  seed: 250104                              # ì¬í˜„ì„±ì„ ìœ„í•œ ëœë¤ ì‹œë“œ
  device: 'cuda'                            # 'cuda', 'cpu', or 'mps'
  data_root: '/path/to/datasets'            # âš ï¸ ìˆ˜ì • í•„ìš”
  save_root: '/path/to/results'             # âš ï¸ ìˆ˜ì • í•„ìš”
```

### ì‹¤í—˜ ì„¤ì •

```yaml
experiment:
  experiment_name: 'my_experiment'          # ì‹¤í—˜ ì´ë¦„
  phase: 'train'                            # 'train' or 'validation'
  batch_size: 8                             # ë°°ì¹˜ í¬ê¸°
  num_workers: 4                            # DataLoader worker ìˆ˜
```

### ìƒ˜í”Œë§ ì „ëµ

```yaml
experiment:
  # Undersampling (negative ìƒ˜í”Œ ì¤„ì´ê¸°)
  enable_undersampling: false
  num_subsample: 12                         # Fold ê°œìˆ˜
  subsample_index: 0                        # ì‚¬ìš©í•  fold (0~11)
  
  # Oversampling (positive ìƒ˜í”Œ ëŠ˜ë¦¬ê¸°)
  enable_oversampling: true
  num_oversample: 13                        # ë³µì œ íšŸìˆ˜
```

### ëª¨ë¸ ì„¤ì •

```yaml
model:
  # Transformer
  transformer_d_model: 256
  transformer_nhead: 8
  transformer_num_layers: 3
  
  # ConvLSTM
  convlstm_hidden_channels: 64
  convlstm_num_layers: 2
  
  # Cross-Modal Fusion
  fusion_num_heads: 4
```

### í•™ìŠµ ì„¤ì •

```yaml
training:
  num_epochs: 10
  learning_rate: 0.0002
  optimizer: 'adam'                         # 'adam' or 'sgd'
  
  # Regression loss
  loss_type: 'mse'                          # 'mse' or 'mae'
  
  # Contrastive loss
  contrastive_type: 'mse'                   # 'mse' or 'infonce'
  contrastive_temperature: 0.3              # InfoNCE temperature (if used)
  lambda_contrastive: 0.1                   # Contrastive loss weight
  
  # Logging
  report_freq: 100                          # ë¡œê·¸ ì¶œë ¥ ë¹ˆë„ (ë°°ì¹˜ ë‹¨ìœ„)
  model_save_freq: 1                        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë¹ˆë„ (epoch ë‹¨ìœ„)
```

### ê²€ì¦ ì„¤ì •

```yaml
validation:
  checkpoint_path: /path/to/model.pth       # âš ï¸ ìˆ˜ì • í•„ìš”
  output_dir: /path/to/output               # âš ï¸ ìˆ˜ì • í•„ìš”
  compute_alignment: true                   # Feature alignment ê³„ì‚° ì—¬ë¶€
```

## ğŸ“Š ì¶œë ¥ ê²°ê³¼

### í•™ìŠµ (`train.py`)

```
results/{experiment_name}/
â”œâ”€â”€ checkpoint/
â”‚   â”œâ”€â”€ best_model.pth                    # Best model (loss ê¸°ì¤€)
â”‚   â”œâ”€â”€ model_epoch1.pth                  # Epochë³„ ì²´í¬í¬ì¸íŠ¸
â”‚   â”œâ”€â”€ model_epoch2.pth
â”‚   â””â”€â”€ model_final.pth                   # ìµœì¢… ëª¨ë¸
â”œâ”€â”€ log/
â”‚   â”œâ”€â”€ training_YYYYMMDD_HHMMSS.log     # í•™ìŠµ ë¡œê·¸
â”‚   â”œâ”€â”€ training_history.json            # Epochë³„ metrics
â”‚   â””â”€â”€ training_curves.png              # í•™ìŠµ ê³¡ì„  ê·¸ë˜í”„
â””â”€â”€ snapshot/
    â””â”€â”€ (training snapshots if enabled)
```

### ê²€ì¦ (`validation.py`)

```
{output_dir}/
â”œâ”€â”€ validation_results.txt                # ìš”ì•½ í…ìŠ¤íŠ¸
â””â”€â”€ validation_results.csv                # ìƒì„¸ ê²°ê³¼ CSV
```

## ğŸ” ì£¼ìš” ê¸°ëŠ¥

### 1. ìë™ Metrics ì¶”ì 

í•™ìŠµ ì¤‘ metricsê°€ ìë™ìœ¼ë¡œ ì¶”ì ë˜ê³  ë¡œê¹…ë©ë‹ˆë‹¤:

```python
trainer = Trainer(...)
history = trainer.fit(dataloader, num_epochs)

# ìë™ìœ¼ë¡œ:
# - ë°°ì¹˜ë³„ metrics ê³„ì‚°
# - ì£¼ê¸°ì  ë¡œê¹… (report_freq)
# - Epochë³„ ìš”ì•½
# - Best model ìë™ ì €ì¥
# - í•™ìŠµ ê³¡ì„  ìë™ í”Œë¡¯
```

### 2. ì²´ê³„ì ì¸ Checkpoint ê´€ë¦¬

```python
# Best model ìë™ ì €ì¥
checkpoint_manager.save_if_best(model, optimizer, epoch, loss)

# ì£¼ê¸°ì  ì €ì¥ (model_save_freq)
checkpoint_manager.save_periodic(model, optimizer, epoch, loss)

# ìµœì¢… ëª¨ë¸ ì €ì¥
checkpoint_manager.save(..., 'model_final.pth')
```

### 3. ì™„ì „í•œ ì¬í˜„ì„±

```python
# Configì—ì„œ ì‹œë“œ ì„¤ì •
environment:
  seed: 250104

# ìë™ìœ¼ë¡œ ëª¨ë“  ëœë¤ì„± ì œì–´:
# - Python random
# - NumPy random
# - PyTorch random (CPU & GPU)
# - CUDA backends
# - DataLoader shuffling
# - Sampling strategies
# - Data augmentation
```

### 4. ìœ ì—°í•œ Loss ì„¤ì •

```yaml
# Configë§Œ ìˆ˜ì •í•˜ë©´ ì¦‰ì‹œ ì ìš©
training:
  contrastive_type: 'mse'           # MSE consistency loss
  # ë˜ëŠ”
  contrastive_type: 'infonce'       # InfoNCE contrastive loss
```

**Contrastive Loss ì„ íƒ ê°€ì´ë“œ:**
- **MSE**: ì‘ì€ ë°°ì¹˜ ì‚¬ì´ì¦ˆ (<32), ë” ì•ˆì •ì 
- **InfoNCE**: í° ë°°ì¹˜ ì‚¬ì´ì¦ˆ (>32), ë” ê°•ë ¥í•œ í‘œí˜„ í•™ìŠµ

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. Import ì˜¤ë¥˜

```bash
# ì˜¤ë¥˜
ModuleNotFoundError: No module named 'pipeline'

# í•´ê²°
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰
cd /path/to/project
python train.py --config-name=local_dev
```

### 2. Config íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ

```bash
# ì˜¤ë¥˜
ConfigCompositionException: Cannot find primary config 'local_dev'

# í•´ê²°
# configs/ ë””ë ‰í† ë¦¬ í™•ì¸
ls configs/local_dev.yaml

# ë˜ëŠ” ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
python train.py --config-path=/absolute/path/to/configs --config-name=local_dev
```

### 3. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±

```yaml
# Config ìˆ˜ì •
experiment:
  batch_size: 1              # ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
  num_workers: 0             # Worker ìˆ˜ ì¤„ì´ê¸°

model:
  transformer_d_model: 128   # ëª¨ë¸ í¬ê¸° ì¤„ì´ê¸°
  convlstm_hidden_channels: 32
```

### 4. í•™ìŠµ ì†ë„ ëŠë¦¼

```yaml
# Config ìµœì í™”
experiment:
  num_workers: 4             # CPU ì½”ì–´ ìˆ˜ì— ë§ê²Œ ì¡°ì •
  batch_size: 8              # GPU ë©”ëª¨ë¦¬ í—ˆìš© ë²”ìœ„ ë‚´ ìµœëŒ€

# DataLoader ìë™ ìµœì í™”:
# - persistent_workers=True
# - prefetch_factor=2
# - pin_memory=True (CUDA ì‚¬ìš© ì‹œ)
```

### 5. ì¬í˜„ì„±ì´ ë³´ì¥ë˜ì§€ ì•ŠìŒ

```yaml
# 1. ì‹œë“œê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
environment:
  seed: 250104

# 2. num_workers í™•ì¸
experiment:
  num_workers: 0  # ì™„ì „í•œ ì¬í˜„ì„±ì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
  # ë˜ëŠ” num_workers > 0ì´ë©´ worker_init_fnì´ ìë™ ì ìš©ë¨
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™” íŒ

### 1. DataLoader ìµœì í™”

```yaml
experiment:
  batch_size: 16             # GPUì— ë§ê²Œ ìµœëŒ€í•œ í¬ê²Œ
  num_workers: 4             # CPU ì½”ì–´ ìˆ˜ (ë³´í†µ 4-8)
```

### 2. ëª¨ë¸ í¬ê¸° ì¡°ì •

```yaml
# í° GPU (V100, A100)
model:
  transformer_d_model: 512
  convlstm_hidden_channels: 128

# ì‘ì€ GPU (RTX 2080, 3070)
model:
  transformer_d_model: 256
  convlstm_hidden_channels: 64

# CPU only
model:
  transformer_d_model: 128
  convlstm_hidden_channels: 32
```

### 3. í˜¼í•© ì •ë°€ë„ í•™ìŠµ (AMP)

í˜„ì¬ ì½”ë“œì—ëŠ” í¬í•¨ë˜ì§€ ì•Šì•˜ì§€ë§Œ, í•„ìš”ì‹œ ì¶”ê°€ ê°€ëŠ¥:

```python
# trainers.pyì˜ Trainer.train_step()ì— ì¶”ê°€
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

with autocast():
    outputs = model(inputs, sdo)
    loss = criterion(outputs, targets)

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

## ğŸ”§ ê°œë°œ ê°€ì´ë“œ

### ìƒˆ Loss í•¨ìˆ˜ ì¶”ê°€

```python
# losses.pyì— ì¶”ê°€
class MyCustomLoss(nn.Module):
    def __init__(self, param1, param2):
        super().__init__()
        self.param1 = param1
        self.param2 = param2
    
    def forward(self, pred, target):
        # êµ¬í˜„
        loss = ...
        return loss

# create_loss_functions() ìˆ˜ì •
if config.training.loss_type == 'my_custom':
    criterion = MyCustomLoss(param1=..., param2=...)
```

### ìƒˆ Metric ì¶”ê°€

```python
# trainers.pyì˜ MetricsTracker.reset() ìˆ˜ì •
def reset(self):
    self.metrics = {
        'loss': [],
        'mae': [],
        'my_metric': [],  # ì¶”ê°€
        # ...
    }

# Trainer.train_step()ì—ì„œ ê³„ì‚°
def train_step(self, data_dict):
    # ...
    my_metric = compute_my_metric(outputs, targets)
    
    return {
        'loss': total_loss.item(),
        'my_metric': my_metric,  # ì¶”ê°€
        # ...
    }
```

### ìƒˆ ë°ì´í„° ì¦ê°• ì¶”ê°€

```python
# pipeline.pyì˜ DataProcessor.apply_augmentation() ìˆ˜ì •
def apply_augmentation(self, input_array, sample_idx, file_name):
    rng = np.random.RandomState(seed)
    
    # ê¸°ì¡´ ì¦ê°•
    factors = np.array([0.8, 0.9, 1.0, 1.1, 1.2])
    augmented = input_array * rng.choice(factors, size=input_array.shape)
    
    # ìƒˆ ì¦ê°• ì¶”ê°€
    if rng.random() > 0.5:
        augmented = my_custom_augmentation(augmented, rng)
    
    return augmented
```

## ğŸ“Š ë°ì´í„° í¬ë§·

### HDF5 íŒŒì¼ êµ¬ì¡°

```
data_file.h5
â”œâ”€â”€ sdo_193              # SDO 193Ã… ì±„ë„ (T, H, W)
â”œâ”€â”€ sdo_211              # SDO 211Ã… ì±„ë„ (T, H, W)
â”œâ”€â”€ sdo_magnetogram      # SDO Magnetogram (T, H, W)
â”œâ”€â”€ omni_Bx_GSE_GSM_nT   # OMNI ë³€ìˆ˜ë“¤ (T,)
â”œâ”€â”€ omni_By_GSM_nT
â””â”€â”€ ...
```

### CSV íŒŒì¼ êµ¬ì¡°

```csv
file_name,class_day1,class_day2,...
sample_001.h5,0,1,...
sample_002.h5,1,1,...
```

## ğŸ¤ ê¸°ì—¬ ê°€ì´ë“œ

1. **ì½”ë“œ ìŠ¤íƒ€ì¼**: PEP 8 ì¤€ìˆ˜
2. **Docstring**: Google style docstring ì‚¬ìš©
3. **íƒ€ì… íŒíŠ¸**: ê°€ëŠ¥í•œ ëª¨ë“  í•¨ìˆ˜ì— íƒ€ì… íŒíŠ¸ ì¶”ê°€
4. **í…ŒìŠ¤íŠ¸**: ì£¼ìš” ê¸°ëŠ¥ì— ëŒ€í•œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

## ğŸ“„ ë¼ì´ì„ ìŠ¤

(í”„ë¡œì íŠ¸ ë¼ì´ì„ ìŠ¤ ëª…ì‹œ)

## ğŸ‘¥ ì €ì

- Eunsu Park (KASI - Korea Astronomy and Space Science Institute)

## ğŸ“§ ë¬¸ì˜

 - eunsupark@kasi.re.kr (work)
 - phd.choux@gmail.com (home)

## ğŸ™ ê°ì‚¬ì˜ ê¸€

- SDO ë°ì´í„°: NASA Solar Dynamics Observatory
- OMNI ë°ì´í„°: NASA OMNIWeb

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

- ì—…ë°ì´íŠ¸ ì˜ˆì •