# Base Configuration for Multi-Modal Solar Wind Prediction Model
# This file contains shared settings across all environments.
# Environment-specific configs (local.yaml, wulver.yaml) override these values.

defaults:
  - _self_
  - override hydra/job_logging: none
  - override hydra/hydra_logging: none

hydra:
  output_subdir: null
  run:
    dir: .
  job:
    chdir: false

# =============================================================================
# Experiment Settings
# =============================================================================
experiment:
  name: "base"
  seed: 250104
  batch_size: 4

# =============================================================================
# Sampling Settings (Undersampling for class imbalance)
# =============================================================================
sampling:
  enable_undersampling: false
  num_subsamples: 14
  subsample_index: 0
  # Input days: negative values (days before reference time)
  # Day -7 = 7 days before, Day -1 = 1 day before
  input_days:
    - -7
    - -6
    - -5
    - -4
    - -3
    - -2
    - -1
  # Target days: positive values (days after reference time)
  # Day 1 = 0-24h, Day 2 = 24-48h, Day 3 = 48-72h
  target_days:
    - 1
    - 2
    - 3

# =============================================================================
# Environment Settings (Override in local.yaml / wulver.yaml)
# =============================================================================
environment:
  device: "cpu"
  data_root: ""
  save_root: ""
  num_workers: 0

# =============================================================================
# Data Settings
# =============================================================================
data:
  # Dataset naming convention
  # CSV files: {dataset_name}_{dataset_suffix}_{phase}.csv
  # Example: original_64_full_train.csv, original_64_full_validation.csv
  dataset_name: "original_64"
  dataset_suffix: "full"

  # ---------------------------------------------------------------------------
  # SDO (Solar Dynamics Observatory) image settings
  # Data structure: -7 days to reference time, 6-hour intervals
  # Total: 28 timesteps (index 0-27), 4 points per day
  # Actual range determined by: sampling.input_days
  # ---------------------------------------------------------------------------
  sdo:
    wavelengths:
      - "aia_193"
      - "aia_211"
      - "hmi_magnetogram"
    image_size: 64
    interval_hours: 6          # Used for day-to-index conversion
    base_offset_hours: -168    # Data starts at -7 days = -168 hours

  # ---------------------------------------------------------------------------
  # OMNI solar wind data settings
  # Data structure: -7 days to +3 days, 3-hour intervals
  # Total: 80 timesteps (index 0-79), 8 points per day
  # Input range determined by: sampling.input_days
  # Target range determined by: sampling.target_days
  # ---------------------------------------------------------------------------
  omni:
    interval_hours: 3          # Used for day-to-index conversion
    base_offset_hours: -168    # Data starts at -7 days = -168 hours

    # Input variables (time range from sampling.input_days)
    input:
      variables:
        - "bx_gse_gsm_nt"
        - "by_gsm_nt"
        - "bz_gsm_nt"
        - "b_magnitude_of_avg_field_vector_nt"
        - "plasma_flow_speed_km_s"
        - "proton_density_n_cm3"
        - "proton_temperature_k"
        - "kp_index"
        - "ap_index_nt"
        - "dst_index_nt"
        - "f10_7_index_sfu"
        - "sunspot_number_r"

    # Target variables (time range from sampling.target_days)
    target:
      variables:
        - "ap_index_nt"

  # ---------------------------------------------------------------------------
  # Legacy settings (DEPRECATED - for backward compatibility only)
  # These are ONLY used if sampling.input_days/target_days are NOT set.
  # Current setup uses sampling.* so these are ignored.
  # ---------------------------------------------------------------------------
  wavelengths:
    - "aia_193"
    - "aia_211"
    - "hmi_magnetogram"
  sdo_image_size: 64
  sdo_start_index: 12      # Equivalent to input_days=[-4,-3,-2,-1]
  sdo_end_index: 28        # Up to reference time (4 points/day × 4 days = 16)

  input_variables:
    - "bx_gse_gsm_nt"
    - "by_gsm_nt"
    - "bz_gsm_nt"
    - "b_magnitude_of_avg_field_vector_nt"
    - "plasma_flow_speed_km_s"
    - "proton_density_n_cm3"
    - "proton_temperature_k"
    - "kp_index"
    - "ap_index_nt"
    - "dst_index_nt"
    - "f10_7_index_sfu"
    - "sunspot_number_r"
  input_start_index: 0     # Equivalent to input_days=[-7,-6,...,-1]
  input_end_index: 56      # Up to reference time (8 points/day × 7 days = 56)

  target_variables:
    - "ap_index_nt"
  target_start_index: 56   # Equivalent to target_days=[1,2,3]
  target_end_index: 80     # Day +1 to +3 (8 points/day × 3 days = 24)

  # ---------------------------------------------------------------------------
  # Normalization Settings
  # Methods: zscore, log_zscore, log1p_zscore, minmax, robust
  # ---------------------------------------------------------------------------
  normalization:
    default: "zscore"
    methods:
      # Type A: Positive/Negative values (symmetric) - Z-score
      bx_gse_gsm_nt: "zscore"
      by_gsm_nt: "zscore"
      bz_gsm_nt: "zscore"
      dst_index_nt: "zscore"

      # Type B: Positive only, long-tail distribution - Log + Z-score
      plasma_flow_speed_km_s: "log_zscore"
      proton_density_n_cm3: "log_zscore"
      proton_temperature_k: "log_zscore"
      b_magnitude_of_avg_field_vector_nt: "log_zscore"
      f10_7_index_sfu: "log_zscore"

      # Type C: Geomagnetic/Solar indices (includes 0) - Log1p + Z-score
      ap_index_nt: "log1p_zscore"
      kp_index: "log1p_zscore"
      sunspot_number_r: "log1p_zscore"

# =============================================================================
# Model Architecture
# =============================================================================
model:
  # Model type selection:
  # - "convlstm": SDO images only (ConvLSTM)
  # - "transformer": OMNI time series only (Transformer)
  # - "fusion": Both modalities with cross-modal attention
  # - "baseline": Both modalities with Conv3D + Linear (Son et al. 2023 style)
  model_type: "fusion"
  # model_type: "convlstm"
  # model_type: "transformer"
  # model_type: "baseline"

  # Shared dimension across modalities
  d_model: 128              # 256 → 128 (lightweight)

  # Transformer encoder (for OMNI time series)
  transformer_nhead: 4      # 8 → 4 (must divide d_model)
  transformer_num_layers: 2  # 3 → 2 (lightweight)
  transformer_dim_feedforward: 256  # 512 → 256 (lightweight)
  transformer_dropout: 0.1

  # ConvLSTM (for SDO images)
  convlstm_input_channels: 3
  convlstm_hidden_channels: 32  # 64 → 32 (lightweight)
  convlstm_kernel_size: 3
  convlstm_num_layers: 2

  # Cross-modal fusion (only used when model_type="fusion")
  fusion_num_heads: 4       # must divide d_model
  fusion_dropout: 0.1

  # Baseline model (only used when model_type="baseline")
  # Based on Son et al. (2023) - Conv3D + Linear fusion
  baseline_dropout: 0.1

  # Output sequence length (derived from target indices, but can be overridden)
  output_seq_len: 24

# =============================================================================
# Training Settings
# =============================================================================
training:
  # Loss functions
  # Options: mse, mae, huber, weighted_mse, solar_wind_weighted
  regression_loss_type: "solar_wind_weighted"
  huber_delta: 10.0  # Only used if regression_loss_type='huber'
  contrastive_loss_type: "consistency"  # consistency, infonce
  contrastive_temperature: 0.3  # Only used if contrastive_loss_type='infonce'
  lambda_contrastive: 0.5  # Weight for contrastive loss

  # ---------------------------------------------------------------------------
  # Contrastive Warmup Settings
  # Gradually decrease lambda_contrastive from lambda_start to lambda_end
  # ---------------------------------------------------------------------------
  contrastive_warmup:
    enable: false            # Set to true to enable warmup
    warmup_epochs: 10        # Number of epochs for warmup
    lambda_start: 1.0        # Initial lambda (high contrastive weight)
    lambda_end: 0.2          # Final lambda (low contrastive weight)

  # ---------------------------------------------------------------------------
  # General Weighted MSE Settings (regression_loss_type='weighted_mse')
  # Applies higher weights to samples with target values above threshold
  # ---------------------------------------------------------------------------
  weighted_mse:
    threshold: 50.0      # Target value threshold for weight assignment
    high_weight: 10.0    # Weight for samples with target > threshold
    low_weight: 1.0      # Weight for samples with target <= threshold

  # ---------------------------------------------------------------------------
  # Solar Wind Weighted Loss Settings (regression_loss_type='solar_wind_weighted')
  # Applies weights based on NOAA geomagnetic activity scale (Ap Index)
  # ---------------------------------------------------------------------------
  solar_wind_weighted:
    base_loss: "mse"              # Base loss type: mse, mae, huber
    weighting_mode: "multi_tier"  # threshold, continuous, multi_tier
    combine_temporal: true        # Combine with temporal weighting (future emphasis)
    temporal_weight_range:        # Start and end weights for temporal weighting
      - 0.5
      - 1.0
    # Settings for 'threshold' mode
    threshold: 30.0               # Ap threshold for binary weighting
    high_weight: 10.0             # Weight for Ap > threshold
    # Settings for 'continuous' mode
    alpha: 5.0                    # Scale factor: w = 1 + alpha * (Ap/400)^beta
    beta: 1.5                     # Power factor
    # Denormalization: convert normalized targets back to raw Ap values for
    # correct tier boundary comparison (NOAA tiers are defined in raw Ap units)
    denormalize: true             # Recommended: true (requires statistics file)

  # Optimizer
  optimizer: "adam"  # adam, sgd
  learning_rate: 0.0002
  weight_decay: 0.0  # L2 regularization (disabled)

  # ---------------------------------------------------------------------------
  # Learning Rate Schedule
  # ---------------------------------------------------------------------------
  # Scheduler type: "reduce_on_plateau", "cosine_annealing", "cosine_warmup"
  scheduler_type: "reduce_on_plateau"

  # ReduceLROnPlateau settings (scheduler_type="reduce_on_plateau")
  scheduler_factor: 0.5  # Factor to reduce LR by
  scheduler_patience: 5  # Epochs to wait before reducing LR

  # Cosine Annealing settings (scheduler_type="cosine_annealing" or "cosine_warmup")
  cosine_annealing:
    T_0: 10              # First restart period (epochs)
    T_mult: 2            # Period multiplier after each restart
    eta_min: 1.0e-6      # Minimum learning rate

  # LR Warmup settings (works with all schedulers)
  # Meaning: 초기 학습률을 낮게 시작하여 점진적으로 증가시킴
  #          → 학습 초기의 불안정성을 줄이고 더 나은 local minima로 수렴
  lr_warmup:
    enable: false        # Set to true to enable warmup
    warmup_epochs: 5     # Number of epochs for linear warmup
    warmup_start_factor: 0.1  # Start at 10% of base learning rate

  # ---------------------------------------------------------------------------
  # Gradient Accumulation
  # Meaning: 여러 미니배치의 gradient를 누적 후 한 번에 업데이트
  #          → 실제 배치 크기를 키우는 효과 (메모리 제한 우회)
  #          → 학습 안정성 향상, gradient 추정 분산 감소
  # ---------------------------------------------------------------------------
  gradient_accumulation_steps: 1  # 1 = disabled, 4 = accumulate 4 batches

  # Gradient clipping
  gradient_clip_max_norm: 1.0

  # Training loop
  epochs: 100
  report_freq: 100
  model_save_freq: 20

  # ---------------------------------------------------------------------------
  # Early Stopping
  # Meaning: validation loss가 개선되지 않으면 훈련 조기 종료
  #          → 오버피팅 방지, 최적 시점에서 모델 저장
  # ---------------------------------------------------------------------------
  early_stopping_patience: 10  # Stop if no improvement for N epochs
  early_stopping_min_delta: 0.0  # Minimum change to qualify as improvement

  # Plotting (generates prediction plots at each report_freq)
  enable_plot: true

  # Two-stage training: load pretrained checkpoint from Stage 1
  # Path relative to save_root (e.g., "experiment_s1/checkpoint/model_best.pth")
  pretrained_checkpoint: null

# =============================================================================
# Validation Settings
# =============================================================================
validation:
  # Path resolution: specify either 'epoch' OR explicit paths
  # If epoch is set and paths are empty, paths are auto-generated:
  #   checkpoint_path: {save_root}/{experiment.name}/checkpoint/model_epoch_{XXXX}.pth
  #   output_dir: {save_root}/{experiment.name}/validation/epoch_{XXXX}
  # Epoch can be: integer (10, 100), "best" (model_best.pth), or "final" (model_final.pth)
  epoch: null              # Set to auto-generate paths (e.g., 10, "best", "final")
  checkpoint_path: ""      # Explicit path (takes priority over epoch)
  output_dir: ""           # Explicit path (takes priority over epoch)
  compute_alignment: true
  save_plots: true   # Save prediction plots for each sample
  save_npz: true     # Save NPZ files for each sample
  report_freq: 50    # Log progress every N batches

# =============================================================================
# Test Settings (Inference with or without ground truth)
# =============================================================================
test:
  epoch: null              # Set to auto-generate paths
  checkpoint_path: ""      # Explicit path (takes priority over epoch)
  output_dir: ""           # Explicit path (takes priority over epoch)
  report_freq: 50    # Log progress every N batches
  save_plots: true   # Save prediction plots for each sample
  save_npz: true     # Save NPZ files for each sample

# =============================================================================
# Monte Carlo Dropout Settings
# =============================================================================
mcd:
  epoch: null              # Set to auto-generate paths
  checkpoint_path: ""      # Explicit path (takes priority over epoch)
  output_dir: ""           # Explicit path (takes priority over epoch)
  num_mc_samples: 100      # Number of MC samples for uncertainty estimation
  create_plots: true       # Generate prediction plots with uncertainty bands
  n_std: 2.0               # Number of std deviations for uncertainty band (±nσ)

# =============================================================================
# Saliency Analysis Settings
# =============================================================================
saliency:
  epoch: null              # Set to auto-generate paths (uses validation checkpoint)
  checkpoint_path: ""      # Explicit path (takes priority over epoch)
  output_dir: ""           # Explicit path (takes priority over epoch)
  ig_steps: 50           # Integrated Gradients integration steps
  create_plots: true     # Generate visualization plots

# =============================================================================
# Attention Analysis Settings
# =============================================================================
attention:
  epoch: null              # Set to auto-generate paths (uses validation checkpoint)
  checkpoint_path: ""      # Explicit path (takes priority over epoch)
  output_dir: ""           # Explicit path (takes priority over epoch)
  create_plots: false    # Generate visualization plots (default false for speed)
