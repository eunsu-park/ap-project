"""
Cross-Modal Fusionì˜ ê°€ì¤‘ì¹˜ í™•ì¸

ë¬¸ì œ:
ConvLSTM featuresê°€ ë„ˆë¬´ ì‘ê±°ë‚˜ fusionì—ì„œ ë¬´ì‹œë˜ëŠ”ê°€?
"""

import torch
import numpy as np
from pathlib import Path
import hydra
from omegaconf import DictConfig

from networks import create_model
from pipeline import create_dataloader


def diagnose_fusion(model, dataloader, device='cpu'):
    """Cross-Modal Fusion ì§„ë‹¨"""
    
    print("\n" + "="*70)
    print("CROSS-MODAL FUSION DIAGNOSTIC")
    print("="*70)
    
    batch = next(iter(dataloader))
    solar_wind = batch['inputs'][:1].to(device)
    images = batch['sdo'][:1].to(device)
    
    model.eval()
    
    # 1. ê° ëª¨ë“ˆì˜ ì¶œë ¥ í¬ê¸° ë¹„êµ
    print("\n1. Feature Magnitude Comparison")
    print("-" * 70)
    
    with torch.no_grad():
        # Transformer features
        transformer_feat = model.transformer_model(solar_wind)
        
        # ConvLSTM features
        convlstm_feat = model.convlstm_model(images)
        
        # Fused features
        fused_feat = model.cross_modal_fusion(transformer_feat, convlstm_feat)
        
        print(f"Transformer output:")
        print(f"  Shape: {transformer_feat.shape}")
        print(f"  Mean:  {transformer_feat.abs().mean():.6f}")
        print(f"  Std:   {transformer_feat.std():.6f}")
        print(f"  Max:   {transformer_feat.abs().max():.6f}")
        
        print(f"\nConvLSTM output:")
        print(f"  Shape: {convlstm_feat.shape}")
        print(f"  Mean:  {convlstm_feat.abs().mean():.6f}")
        print(f"  Std:   {convlstm_feat.std():.6f}")
        print(f"  Max:   {convlstm_feat.abs().max():.6f}")
        
        print(f"\nFused output:")
        print(f"  Shape: {fused_feat.shape}")
        print(f"  Mean:  {fused_feat.abs().mean():.6f}")
        print(f"  Std:   {fused_feat.std():.6f}")
        
        # í¬ê¸° ë¹„ìœ¨
        t_mag = transformer_feat.abs().mean().item()
        c_mag = convlstm_feat.abs().mean().item()
        
        print(f"\nğŸ“Š Magnitude Ratio:")
        print(f"  Transformer / ConvLSTM = {t_mag / (c_mag + 1e-10):.2f}x")
        
        if t_mag > c_mag * 100:
            print("\nğŸ”´ CRITICAL: Transformer features 100x larger!")
            print("   â†’ Cross-modal fusion will ignore ConvLSTM")
            print("   â†’ Need to normalize or rescale features")
        elif t_mag > c_mag * 10:
            print("\nâš ï¸  WARNING: Transformer features 10x larger")
            print("   â†’ ConvLSTM has minimal influence")
        else:
            print("\nâœ“ Feature magnitudes are balanced")
    
    # 2. Fusion ê°€ì¤‘ì¹˜ í™•ì¸ (attention ê¸°ë°˜ì¸ ê²½ìš°)
    print("\n2. Fusion Mechanism Analysis")
    print("-" * 70)
    
    try:
        # Fusion layerì˜ íŒŒë¼ë¯¸í„° í™•ì¸
        fusion = model.cross_modal_fusion
        
        # Attention weights ì¶”ì¶œ (êµ¬í˜„ì— ë”°ë¼ ë‹¤ë¦„)
        if hasattr(fusion, 'attention'):
            print("âœ“ Fusion uses attention mechanism")
            
            with torch.no_grad():
                # Attention ê³„ì‚°
                attn = fusion.attention(transformer_feat, convlstm_feat)
                
                print(f"\nAttention weights:")
                print(f"  Transformer: {attn[0].mean():.4f}")
                print(f"  ConvLSTM:    {attn[1].mean():.4f}")
                
                if attn[1].mean() < 0.1:
                    print("\nğŸ”´ CRITICAL: ConvLSTM attention < 10%!")
                    print("   â†’ Model is ignoring visual features")
                    
        elif hasattr(fusion, 'gate'):
            print("âœ“ Fusion uses gating mechanism")
            
            # Gate ì¶œë ¥ í™•ì¸
            with torch.no_grad():
                gate = fusion.gate(torch.cat([transformer_feat, convlstm_feat], dim=-1))
                print(f"\nGate values: {gate.mean():.4f} Â± {gate.std():.4f}")
                
                if gate.mean() < 0.1 or gate.mean() > 0.9:
                    print("\nâš ï¸  Gate is saturated (close to 0 or 1)")
                    print("   â†’ One modality dominates")
                    
        else:
            print("âš ï¸  Fusion type unknown")
            print("   â†’ Check fusion implementation")
            
    except Exception as e:
        print(f"âš ï¸  Error analyzing fusion: {e}")
    
    # 3. Ablation test
    print("\n3. Ablation Test")
    print("-" * 70)
    
    with torch.no_grad():
        # Full model
        output_full = model(solar_wind, images)
        
        # Without ConvLSTM (zero images)
        output_no_conv = model(solar_wind, torch.zeros_like(images))
        
        # Without Transformer (zero OMNI)
        output_no_trans = model(torch.zeros_like(solar_wind), images)
        
        diff_no_conv = (output_full - output_no_conv).abs().mean().item()
        diff_no_trans = (output_full - output_no_trans).abs().mean().item()
        
        print(f"Prediction change when removing:")
        print(f"  ConvLSTM:    {diff_no_conv:.6f}")
        print(f"  Transformer: {diff_no_trans:.6f}")
        
        print(f"\nğŸ“Š Contribution Ratio:")
        print(f"  Transformer / ConvLSTM = {diff_no_trans / (diff_no_conv + 1e-10):.2f}x")
        
        if diff_no_conv < 1e-4:
            print("\nğŸ”´ CRITICAL: Removing ConvLSTM has NO effect!")
            print("   â†’ Model is NOT using visual features")
        elif diff_no_conv < diff_no_trans * 0.1:
            print("\nâš ï¸  WARNING: ConvLSTM contributes < 10%")
            print("   â†’ Transformer dominates prediction")
    
    # 4. ìµœì¢… ì§„ë‹¨
    print("\n" + "="*70)
    print("DIAGNOSIS SUMMARY")
    print("="*70)
    
    print("\nğŸ’¡ RECOMMENDED ACTIONS:")
    
    if c_mag < t_mag * 0.01:
        print("\n1. Feature Normalization:")
        print("   - Add LayerNorm before fusion")
        print("   - Or manually rescale ConvLSTM output")
        
    if diff_no_conv < 1e-4:
        print("\n2. Retrain with:")
        print("   - Higher learning rate for ConvLSTM")
        print("   - Separate optimizer for each branch")
        print("   - Auxiliary loss on ConvLSTM features")
        
    print("\n3. Architecture Changes:")
    print("   - Use learnable fusion weights")
    print("   - Add skip connections")
    print("   - Increase ConvLSTM hidden size")


@hydra.main(config_path="./configs", config_name="saliency", version_base=None)
def main(config: DictConfig):
    
    checkpoint_path = "/Users/eunsupark/checkpoints/SINGLE_7_1_05/checkpoint/model_epoch0100.pth"
    device = "cpu"
    
    print("="*70)
    print("CROSS-MODAL FUSION DIAGNOSTIC TOOL")
    print("="*70)
    print(f"\nCheckpoint: {checkpoint_path}")
    
    # Load model
    model = create_model(config)
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    if 'model_state_dict' in checkpoint:
        state_dict = checkpoint['model_state_dict']
    elif 'state_dict' in checkpoint:
        state_dict = checkpoint['state_dict']
    else:
        state_dict = checkpoint
    
    model.load_state_dict(state_dict)
    model = model.to(device)
    
    print("âœ“ Model loaded")
    
    # Load data
    dataloader = create_dataloader(config, phase='validation')
    print("âœ“ DataLoader loaded")
    
    # Run diagnostics
    diagnose_fusion(model, dataloader, device)


if __name__ == '__main__':
    main()
