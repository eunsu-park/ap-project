# Solar Wind Prediction - Multimodal Deep Learning

íƒœì–‘í’ ì˜ˆì¸¡ì„ ìœ„í•œ ë©€í‹°ëª¨ë‹¬ ë”¥ëŸ¬ë‹ ëª¨ë¸ì…ë‹ˆë‹¤. Transformer (ì‹œê³„ì—´ ë°ì´í„°)ì™€ ConvLSTM (ìœ„ì„± ì´ë¯¸ì§€)ì„ ê²°í•©í•˜ì—¬ ì§€êµ¬ ìê¸°ê¶Œ êµë€ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” íŠ¹ì§•

### ëª¨ë¸ ì•„í‚¤í…ì²˜
- **Transformer**: OMNI íƒœì–‘í’ ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬
- **ConvLSTM**: SDO ìœ„ì„± ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ì²˜ë¦¬
- **Cross-Modal Fusion**: ë‘ ëª¨ë‹¬ë¦¬í‹° ì •ë³´ í†µí•©
- **Contrastive Learning**: ë©€í‹°ëª¨ë‹¬ íŠ¹ì„± ì •ë ¬

### ì½”ë“œ í’ˆì§ˆ
- âœ… **ëª¨ë“ˆí™”**: ëª…í™•í•œ ì±…ì„ ë¶„ë¦¬ (Trainer, Validator, DataProcessor ë“±)
- âœ… **ì¬í˜„ì„±**: ì™„ì „í•œ ì‹œë“œ ì œì–´ ë° ê²°ì •ì  ì•Œê³ ë¦¬ì¦˜
- âœ… **íš¨ìœ¨ì„±**: ë©”ëª¨ë¦¬ ìµœì í™” ë° DataLoader ìµœì í™”
- âœ… **í™•ì¥ì„±**: ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ ìš©ì´

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
project/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ local_dev.yaml        # ì„¤ì • íŒŒì¼
â”‚
â”œâ”€â”€ Modularized Packages (ìƒˆë¡œìš´ êµ¬ì¡°!)
â”‚   â”œâ”€â”€ datasets/             # ë°ì´í„° íŒŒì´í”„ë¼ì¸ (8 files)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py         # DataConfig
â”‚   â”‚   â”œâ”€â”€ statistics.py     # Normalizer, OnlineStatistics, compute_statistics
â”‚   â”‚   â”œâ”€â”€ io.py             # HDF5Reader
â”‚   â”‚   â”œâ”€â”€ preprocessing.py  # DataProcessor
â”‚   â”‚   â”œâ”€â”€ sampling.py       # SamplingStrategy
â”‚   â”‚   â”œâ”€â”€ dataset.py        # BaseDataset, TrainDataset, ValidationDataset
â”‚   â”‚   â””â”€â”€ dataloader.py     # create_dataloader
â”‚   â”‚
â”‚   â”œâ”€â”€ models/               # ì‹ ê²½ë§ ëª¨ë¸ (6 files)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ convlstm.py       # ConvLSTMCell, ConvLSTMModel
â”‚   â”‚   â”œâ”€â”€ transformer.py    # PositionalEncoding, TransformerEncoderModel
â”‚   â”‚   â”œâ”€â”€ fusion.py         # CrossModalAttention, CrossModalFusion
â”‚   â”‚   â”œâ”€â”€ multimodal.py     # MultiModalModel
â”‚   â”‚   â””â”€â”€ factory.py        # create_model
â”‚   â”‚
â”‚   â”œâ”€â”€ losses/               # Loss í•¨ìˆ˜ë“¤ (5 files)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ contrastive.py    # MultiModalContrastiveLoss, MultiModalMSELoss
â”‚   â”‚   â”œâ”€â”€ regression.py     # WeightedMSELoss, HuberMultiCriteriaLoss, etc.
â”‚   â”‚   â”œâ”€â”€ advanced.py       # AdaptiveWeightLoss, QuantileLoss, etc.
â”‚   â”‚   â””â”€â”€ factory.py        # create_loss_functions, create_loss
â”‚   â”‚
â”‚   â””â”€â”€ utils/                # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (8 files)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ seed.py           # set_seed
â”‚       â”œâ”€â”€ logging_utils.py  # setup_logger, log_message
â”‚       â”œâ”€â”€ device.py         # setup_device
â”‚       â”œâ”€â”€ model_io.py       # load_model
â”‚       â”œâ”€â”€ visualization.py  # save_plot, plotting functions
â”‚       â”œâ”€â”€ metrics.py        # calculate_metrics
â”‚       â””â”€â”€ slurm.py          # WulverSubmitter
â”‚
â”œâ”€â”€ Training & Validation
â”‚   â”œâ”€â”€ trainers.py           # Trainer, MetricsTracker, CheckpointManager
â”‚   â”œâ”€â”€ validators.py         # Validator, MetricsAggregator, ResultsWriter
â”‚   â”œâ”€â”€ train.py              # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ validation.py         # ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
â”‚
â””â”€â”€ Documentation
    â”œâ”€â”€ README.md             # ì´ íŒŒì¼
    â””â”€â”€ CONFIG_GUIDE.md       # ì„¤ì • ê°€ì´ë“œ (ì„ íƒ)
```

**ì£¼ìš” ë³€ê²½ì‚¬í•­:**
- `pipeline.py` â†’ `datasets/` íŒ¨í‚¤ì§€ë¡œ ëª¨ë“ˆí™”
- `networks.py` â†’ `models/` íŒ¨í‚¤ì§€ë¡œ ëª¨ë“ˆí™”
- `losses.py` â†’ `losses/` íŒ¨í‚¤ì§€ë¡œ ëª¨ë“ˆí™” (ë” ë§ì€ loss ì¶”ê°€)
- `utils.py` â†’ `utils/` íŒ¨í‚¤ì§€ë¡œ ëª¨ë“ˆí™”
- `trainers.py`, `validators.py`ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ (ì´ë¯¸ ì˜ êµ¬ì¡°í™”ë¨)

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install torch torchvision
pip install numpy pandas h5py
pip install hydra-core matplotlib

# ë˜ëŠ” requirements.txt ì‚¬ìš©
pip install -r requirements.txt
```

### 2. ì„¤ì • íŒŒì¼ ì¤€ë¹„

`configs/local_dev.yaml` íŒŒì¼ì—ì„œ ê²½ë¡œë¥¼ ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •:

```yaml
environment:
  data_root: '/YOUR/PATH/TO/datasets'      # ë°ì´í„°ì…‹ ê²½ë¡œ
  save_root: '/YOUR/PATH/TO/results'       # ê²°ê³¼ ì €ì¥ ê²½ë¡œ

validation:
  checkpoint_path: /YOUR/PATH/TO/model.pth # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
  output_dir: /YOUR/PATH/TO/output         # ê²€ì¦ ê²°ê³¼ ê²½ë¡œ
```

### 3. í•™ìŠµ

```bash
python train.py --config-name=local_dev
```

### 4. ê²€ì¦

```bash
python validation.py --config-name=local_dev
```

## ğŸ“š ì£¼ìš” ì»´í¬ë„ŒíŠ¸

### 1. datasets/ - ë°ì´í„° íŒŒì´í”„ë¼ì¸

**ì£¼ìš” í´ë˜ìŠ¤ (ëª¨ë“ˆë³„ë¡œ ì •ë¦¬ë¨):**

```python
# datasets/config.py
DataConfig                  # ë°ì´í„° ì„¤ì •

# datasets/statistics.py
Normalizer                  # SDO/OMNI ë°ì´í„° ì •ê·œí™”
OnlineStatistics           # ë©”ëª¨ë¦¬ íš¨ìœ¨ì  í†µê³„ ê³„ì‚°
compute_statistics         # í†µê³„ ê³„ì‚° í—¬í¼ í•¨ìˆ˜

# datasets/sampling.py
SamplingStrategy           # Under/Oversampling ì „ëµ

# datasets/io.py
HDF5Reader                 # HDF5 íŒŒì¼ ì½ê¸°

# datasets/preprocessing.py
DataProcessor              # ë°ì´í„° ì „ì²˜ë¦¬

# datasets/dataset.py
BaseMultimodalDataset      # ê¸°ë³¸ Dataset í´ë˜ìŠ¤
TrainDataset              # í•™ìŠµìš© Dataset (sampling + augmentation)
ValidationDataset         # ê²€ì¦ìš© Dataset (ì›ë³¸ ë°ì´í„°)

# datasets/dataloader.py
create_dataloader()       # DataLoader ìƒì„± íŒ©í† ë¦¬ í•¨ìˆ˜
```

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from datasets import create_dataloader

dataloader = create_dataloader(config, logger)
for batch in dataloader:
    sdo = batch['sdo']          # (B, C, T, H, W)
    inputs = batch['inputs']     # (B, T, C)
    targets = batch['targets']   # (B, T, C)
    labels = batch['labels']     # (B, 1, 1)
```

**ì£¼ìš” ê°œì„ ì‚¬í•­:**
- Train/Validation Dataset ëª…í™•íˆ ë¶„ë¦¬
- ê° ê¸°ëŠ¥ë³„ë¡œ ë…ë¦½ì ì¸ ëª¨ë“ˆ
- ë” ì‰¬ìš´ í…ŒìŠ¤íŠ¸ì™€ ìœ ì§€ë³´ìˆ˜

### 2. models/ - ì‹ ê²½ë§ ëª¨ë¸

**ì£¼ìš” í´ë˜ìŠ¤ (ëª¨ë“ˆë³„ë¡œ ì •ë¦¬ë¨):**

```python
# models/convlstm.py
ConvLSTMCell              # ConvLSTM ì…€
ConvLSTMModel             # ë‹¤ì¸µ ConvLSTM

# models/transformer.py
PositionalEncoding        # ìœ„ì¹˜ ì¸ì½”ë”©
TransformerEncoderModel   # Transformer ì¸ì½”ë”

# models/fusion.py
CrossModalAttention       # Cross-modal attention
CrossModalFusion          # ëª¨ë‹¬ë¦¬í‹° ìœµí•©

# models/multimodal.py
MultiModalModel           # ì „ì²´ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸

# models/factory.py
create_model()            # ëª¨ë¸ ìƒì„± íŒ©í† ë¦¬ í•¨ìˆ˜
```

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from models import create_model

model = create_model(config, logger)
model.to(device)

# Forward pass
outputs, transformer_features, convlstm_features = model(
    solar_wind_input, 
    image_input,
    return_features=True
)
```

**ì£¼ìš” ê°œì„ ì‚¬í•­:**
- ê° ì»´í¬ë„ŒíŠ¸ê°€ ë…ë¦½ì ì¸ íŒŒì¼
- ëª…í™•í•œ ì•„í‚¤í…ì²˜ êµ¬ì¡°
- ì‰¬ìš´ ì»´í¬ë„ŒíŠ¸ êµì²´ ë° ì‹¤í—˜

### 3. losses/ - Loss í•¨ìˆ˜

**ì£¼ìš” í´ë˜ìŠ¤ (ëª¨ë“ˆë³„ë¡œ ì •ë¦¬ë¨):**

```python
# losses/contrastive.py
MultiModalContrastiveLoss   # InfoNCE contrastive loss
MultiModalMSELoss          # MSE consistency loss

# losses/regression.py
WeightedMSELoss            # ì‹œê°„ ê°€ì¤‘ MSE
HuberMultiCriteriaLoss     # Huber + temporal/gradient weighting
MAEOutlierFocusedLoss      # MAE + outlier detection

# losses/advanced.py
AdaptiveWeightLoss         # ì—ëŸ¬ ì ì‘í˜• ê°€ì¤‘ì¹˜
GradientBasedWeightLoss    # ê·¸ë˜ë””ì–¸íŠ¸ ê¸°ë°˜ ê°€ì¤‘ì¹˜
QuantileLoss               # Quantile regression
MultiTaskLoss              # Multi-task learning

# losses/factory.py
create_loss_functions()    # Configì—ì„œ loss ìƒì„±
create_loss()              # ë‹¨ì¼ loss ìƒì„±
```

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from losses import create_loss_functions

reg_criterion, cont_criterion = create_loss_functions(config, logger)

# í•™ìŠµ ì‹œ
reg_loss = reg_criterion(outputs, targets)
cont_loss = cont_criterion(transformer_features, convlstm_features)
total_loss = reg_loss + lambda_contrastive * cont_loss
```

**ì£¼ìš” ê°œì„ ì‚¬í•­:**
- 10+ loss í•¨ìˆ˜ ì œê³µ (ê¸°ì¡´ 2ê°œì—ì„œ í™•ì¥)
- Contrastive / Regression / Advancedë¡œ ì¹´í…Œê³ ë¦¬ ë¶„ë¦¬
- ì—°êµ¬ ì¹œí™”ì  êµ¬ì¡° (ìƒˆ loss ì¶”ê°€ ìš©ì´)

### 4. utils/ - ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜

**ì£¼ìš” í•¨ìˆ˜ (ëª¨ë“ˆë³„ë¡œ ì •ë¦¬ë¨):**

```python
# utils/seed.py
set_seed()                 # ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •

# utils/logging_utils.py
setup_logger()             # Logger ì„¤ì •
log_message()              # ë¡œê¹… í—¬í¼

# utils/device.py
setup_device()             # Device ì„¤ì • (CUDA/MPS/CPU)

# utils/model_io.py
load_model()               # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ

# utils/visualization.py
save_plot()                # ë¹„êµ í”Œë¡¯ ì €ì¥
denormalize_predictions()  # ì˜ˆì¸¡ ì—­ì •ê·œí™”
create_comparison_plot()   # ë¹„êµ í”Œë¡¯ ìƒì„±
save_data_h5()             # HDF5ë¡œ ë°ì´í„° ì €ì¥

# utils/metrics.py
calculate_metrics()        # í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°

# utils/slurm.py
WulverSubmitter            # SLURM ì‘ì—… ì œì¶œ
```

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from utils import set_seed, setup_logger, setup_device, load_model

# í™˜ê²½ ì„¤ì •
set_seed(42, logger)
logger = setup_logger(__name__, log_dir='./logs')
device = setup_device(config, logger)

# ëª¨ë¸ ë¡œë“œ
model = load_model(model, checkpoint_path, device, logger)

# ì‹œê°í™”
from utils import save_plot
save_plot(targets, outputs, var_names, stats, 'path', 'Title', logger)
```

**ì£¼ìš” ê°œì„ ì‚¬í•­:**
- ê° ê¸°ëŠ¥ë³„ë¡œ ë…ë¦½ì ì¸ ëª¨ë“ˆ
- ë” ëª…í™•í•œ í•¨ìˆ˜ ë¶„ë¥˜
- SLURM ì§€ì› ì¶”ê°€

### 5. trainers.py - í•™ìŠµ ê´€ë¦¬

**ì£¼ìš” í´ë˜ìŠ¤:**

```python
MetricsTracker             # í•™ìŠµ metrics ìë™ ì¶”ì 
CheckpointManager          # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬
Trainer                    # ì „ì²´ í•™ìŠµ ë£¨í”„ ê´€ë¦¬
```

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from trainers import Trainer

trainer = Trainer(
    config, model, optimizer, scheduler,
    criterion, contrastive_criterion,
    device, logger
)

history = trainer.fit(dataloader, num_epochs=10)
```

### 6. validators.py - ê²€ì¦ ê´€ë¦¬

**ì£¼ìš” í´ë˜ìŠ¤:**

```python
MetricsAggregator          # ê²€ì¦ metrics ì§‘ê³„
ResultsWriter              # ê²°ê³¼ íŒŒì¼ ì €ì¥
Validator                  # ì „ì²´ ê²€ì¦ ë£¨í”„ ê´€ë¦¬
```

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from validators import Validator

validator = Validator(
    config, model, criterion, device, logger,
    save_plots=True  # ê°œë³„ í”Œë¡¯ ì €ì¥
)
results = validator.validate(dataloader)
```

**í”Œë¡¯ ì €ì¥ ê¸°ëŠ¥:**
- `save_plots=True`: ê° ìƒ˜í”Œë³„ ì˜ˆì¸¡ vs íƒ€ê²Ÿ í”Œë¡¯ ìë™ ì €ì¥
- ê°œë³„ ìƒ˜í”Œ í”Œë¡¯ + ì „ì²´ í‰ê·  í”Œë¡¯ ìƒì„±
- `{output_dir}/plots/` ë””ë ‰í† ë¦¬ì— PNG íŒŒì¼ë¡œ ì €ì¥

## âš™ï¸ ì„¤ì • ê°€ì´ë“œ

### í•„ìˆ˜ ê²½ë¡œ ì„¤ì •

```yaml
environment:
  seed: 250104                              # ì¬í˜„ì„±ì„ ìœ„í•œ ëœë¤ ì‹œë“œ
  device: 'cuda'                            # 'cuda', 'cpu', or 'mps'
  data_root: '/path/to/datasets'            # âš ï¸ ìˆ˜ì • í•„ìš”
  save_root: '/path/to/results'             # âš ï¸ ìˆ˜ì • í•„ìš”
```

### ì‹¤í—˜ ì„¤ì •

```yaml
experiment:
  experiment_name: 'my_experiment'          # ì‹¤í—˜ ì´ë¦„
  phase: 'train'                            # 'train' or 'validation'
  batch_size: 8                             # ë°°ì¹˜ í¬ê¸°
  num_workers: 4                            # DataLoader worker ìˆ˜
```

### ìƒ˜í”Œë§ ì „ëµ

```yaml
experiment:
  # Undersampling (negative ìƒ˜í”Œ ì¤„ì´ê¸°)
  enable_undersampling: false
  num_subsample: 12                         # Fold ê°œìˆ˜
  subsample_index: 0                        # ì‚¬ìš©í•  fold (0~11)
  
  # Oversampling (positive ìƒ˜í”Œ ëŠ˜ë¦¬ê¸°)
  enable_oversampling: true
  num_oversample: 13                        # ë³µì œ íšŸìˆ˜
```

### ëª¨ë¸ ì„¤ì •

```yaml
model:
  # Transformer
  transformer_d_model: 256
  transformer_nhead: 8
  transformer_num_layers: 3
  
  # ConvLSTM
  convlstm_hidden_channels: 64
  convlstm_num_layers: 2
  
  # Cross-Modal Fusion
  fusion_num_heads: 4
```

### í•™ìŠµ ì„¤ì •

```yaml
training:
  num_epochs: 10
  learning_rate: 0.0002
  optimizer: 'adam'                         # 'adam' or 'sgd'
  
  # Regression loss
  loss_type: 'mse'                          # 'mse' or 'mae'
  
  # Contrastive loss
  contrastive_type: 'mse'                   # 'mse' or 'infonce'
  contrastive_temperature: 0.3              # InfoNCE temperature (if used)
  lambda_contrastive: 0.1                   # Contrastive loss weight
  
  # Logging
  report_freq: 100                          # ë¡œê·¸ ì¶œë ¥ ë¹ˆë„ (ë°°ì¹˜ ë‹¨ìœ„)
  model_save_freq: 1                        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë¹ˆë„ (epoch ë‹¨ìœ„)
```

### ê²€ì¦ ì„¤ì •

```yaml
validation:
  checkpoint_path: /path/to/model.pth       # âš ï¸ ìˆ˜ì • í•„ìš”
  output_dir: /path/to/output               # âš ï¸ ìˆ˜ì • í•„ìš”
  compute_alignment: true                   # Feature alignment ê³„ì‚° ì—¬ë¶€
  save_plots: true                          # ê°œë³„ ìƒ˜í”Œ í”Œë¡¯ ì €ì¥ ì—¬ë¶€
```

**save_plots ì˜µì…˜:**
- `true`: ê° ìƒ˜í”Œë³„ ì˜ˆì¸¡ vs íƒ€ê²Ÿ í”Œë¡¯ ì €ì¥ (ê¶Œì¥)
- `false`: í”Œë¡¯ ì €ì¥ ì•ˆ í•¨ (ë¹ ë¥¸ ê²€ì¦ë§Œ í•„ìš”í•  ë•Œ)

í”Œë¡¯ì€ `{output_dir}/plots/` ë””ë ‰í† ë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤.

## ğŸ“Š ì¶œë ¥ ê²°ê³¼

### í•™ìŠµ (`train.py`)

```
results/{experiment_name}/
â”œâ”€â”€ checkpoint/
â”‚   â”œâ”€â”€ best_model.pth                    # Best model (loss ê¸°ì¤€)
â”‚   â”œâ”€â”€ model_epoch1.pth                  # Epochë³„ ì²´í¬í¬ì¸íŠ¸
â”‚   â”œâ”€â”€ model_epoch2.pth
â”‚   â””â”€â”€ model_final.pth                   # ìµœì¢… ëª¨ë¸
â”œâ”€â”€ log/
â”‚   â”œâ”€â”€ training_YYYYMMDD_HHMMSS.log     # í•™ìŠµ ë¡œê·¸
â”‚   â”œâ”€â”€ training_history.json            # Epochë³„ metrics
â”‚   â””â”€â”€ training_curves.png              # í•™ìŠµ ê³¡ì„  ê·¸ë˜í”„
â””â”€â”€ snapshot/
    â””â”€â”€ (training snapshots if enabled)
```

### ê²€ì¦ (`validation.py`)

```
{output_dir}/
â”œâ”€â”€ validation_results.txt                # ìš”ì•½ í…ìŠ¤íŠ¸
â”œâ”€â”€ validation_results.csv                # ìƒì„¸ ê²°ê³¼ CSV
â””â”€â”€ plots/                                # ì˜ˆì¸¡ vs íƒ€ê²Ÿ í”Œë¡¯ë“¤
    â”œâ”€â”€ sample_001.png                   # ê°œë³„ ìƒ˜í”Œ í”Œë¡¯
    â”œâ”€â”€ sample_002.png
    â”œâ”€â”€ ...
    â””â”€â”€ overall_validation_results.png    # ì „ì²´ í‰ê·  í”Œë¡¯
```

**í”Œë¡¯ ë‚´ìš©:**
- ê° íƒ€ê²Ÿ ë³€ìˆ˜ë³„ë¡œ ì‹œê³„ì—´ ê·¸ë˜í”„
- íŒŒë€ìƒ‰ ì„ : ì‹¤ì œ íƒ€ê²Ÿ (Ground Truth)
- ì£¼í™©ìƒ‰ ì„ : ëª¨ë¸ ì˜ˆì¸¡ (Prediction)
- Denormalized ê°’ìœ¼ë¡œ í‘œì‹œ (ì›ë³¸ ìŠ¤ì¼€ì¼)

## ğŸ” ì£¼ìš” ê¸°ëŠ¥

### 0. ëª¨ë“ˆí™”ì˜ ì´ì  (ìƒˆë¡œìš´!)

**ëª…í™•í•œ êµ¬ì¡°:**
- `datasets/`: ëª¨ë“  ë°ì´í„° ê´€ë ¨ ë¡œì§
- `models/`: ëª¨ë“  ì‹ ê²½ë§ ì•„í‚¤í…ì²˜
- `losses/`: ëª¨ë“  loss í•¨ìˆ˜
- `utils/`: ëª¨ë“  ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜

**ì¥ì :**
- âœ… **ìœ ì§€ë³´ìˆ˜**: ì½”ë“œ ìœ„ì¹˜ë¥¼ ì‰½ê²Œ ì°¾ì„ ìˆ˜ ìˆìŒ
- âœ… **í…ŒìŠ¤íŠ¸**: ê° ëª¨ë“ˆì„ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
- âœ… **ì¬ì‚¬ìš©**: í•„ìš”í•œ ë¶€ë¶„ë§Œ import
- âœ… **í˜‘ì—…**: ì—¬ëŸ¬ ì‚¬ëŒì´ ë™ì‹œì— ì‘ì—… ê°€ëŠ¥
- âœ… **í™•ì¥**: ìƒˆ ê¸°ëŠ¥ ì¶”ê°€ê°€ ëª…í™•í•¨

**ì´ì „ vs ì´í›„:**
```python
# ì´ì „ (Monolithic)
from pipeline import create_dataloader        # 950 lines
from networks import create_model             # 927 lines
from losses import create_loss_functions      # 903 lines

# ì´í›„ (Modular)
from datasets import create_dataloader        # 8ê°œ íŒŒì¼ë¡œ ë¶„ë¦¬
from models import create_model               # 6ê°œ íŒŒì¼ë¡œ ë¶„ë¦¬
from losses import create_loss_functions      # 5ê°œ íŒŒì¼ë¡œ ë¶„ë¦¬
from utils import set_seed, setup_logger      # 8ê°œ íŒŒì¼ë¡œ ë¶„ë¦¬
```

### 2. ìë™ Metrics ì¶”ì 

í•™ìŠµ ì¤‘ metricsê°€ ìë™ìœ¼ë¡œ ì¶”ì ë˜ê³  ë¡œê¹…ë©ë‹ˆë‹¤:

```python
trainer = Trainer(...)
history = trainer.fit(dataloader, num_epochs)

# ìë™ìœ¼ë¡œ:
# - ë°°ì¹˜ë³„ metrics ê³„ì‚°
# - ì£¼ê¸°ì  ë¡œê¹… (report_freq)
# - Epochë³„ ìš”ì•½
# - Best model ìë™ ì €ì¥
# - í•™ìŠµ ê³¡ì„  ìë™ í”Œë¡¯
```

### 3. ì²´ê³„ì ì¸ Checkpoint ê´€ë¦¬

```python
# Best model ìë™ ì €ì¥
checkpoint_manager.save_if_best(model, optimizer, epoch, loss)

# ì£¼ê¸°ì  ì €ì¥ (model_save_freq)
checkpoint_manager.save_periodic(model, optimizer, epoch, loss)

# ìµœì¢… ëª¨ë¸ ì €ì¥
checkpoint_manager.save(..., 'model_final.pth')
```

### 4. ì™„ì „í•œ ì¬í˜„ì„±

```python
# Configì—ì„œ ì‹œë“œ ì„¤ì •
environment:
  seed: 250104

# ìë™ìœ¼ë¡œ ëª¨ë“  ëœë¤ì„± ì œì–´:
# - Python random
# - NumPy random
# - PyTorch random (CPU & GPU)
# - CUDA backends
# - DataLoader shuffling
# - Sampling strategies
# - Data augmentation
```

### 5. ìœ ì—°í•œ Loss ì„¤ì •

```yaml
# Configë§Œ ìˆ˜ì •í•˜ë©´ ì¦‰ì‹œ ì ìš©
training:
  contrastive_type: 'mse'           # MSE consistency loss
  # ë˜ëŠ”
  contrastive_type: 'infonce'       # InfoNCE contrastive loss
```

**Contrastive Loss ì„ íƒ ê°€ì´ë“œ:**
- **MSE**: ì‘ì€ ë°°ì¹˜ ì‚¬ì´ì¦ˆ (<32), ë” ì•ˆì •ì 
- **InfoNCE**: í° ë°°ì¹˜ ì‚¬ì´ì¦ˆ (>32), ë” ê°•ë ¥í•œ í‘œí˜„ í•™ìŠµ

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. Import ì˜¤ë¥˜

```bash
# ì˜¤ë¥˜
ModuleNotFoundError: No module named 'pipeline'

# í•´ê²°
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰
cd /path/to/project
python train.py --config-name=local_dev
```

### 2. Config íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ

```bash
# ì˜¤ë¥˜
ConfigCompositionException: Cannot find primary config 'local_dev'

# í•´ê²°
# configs/ ë””ë ‰í† ë¦¬ í™•ì¸
ls configs/local_dev.yaml

# ë˜ëŠ” ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
python train.py --config-path=/absolute/path/to/configs --config-name=local_dev
```

### 3. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±

```yaml
# Config ìˆ˜ì •
experiment:
  batch_size: 1              # ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
  num_workers: 0             # Worker ìˆ˜ ì¤„ì´ê¸°

model:
  transformer_d_model: 128   # ëª¨ë¸ í¬ê¸° ì¤„ì´ê¸°
  convlstm_hidden_channels: 32
```

### 4. í•™ìŠµ ì†ë„ ëŠë¦¼

```yaml
# Config ìµœì í™”
experiment:
  num_workers: 4             # CPU ì½”ì–´ ìˆ˜ì— ë§ê²Œ ì¡°ì •
  batch_size: 8              # GPU ë©”ëª¨ë¦¬ í—ˆìš© ë²”ìœ„ ë‚´ ìµœëŒ€

# DataLoader ìë™ ìµœì í™”:
# - persistent_workers=True
# - prefetch_factor=2
# - pin_memory=True (CUDA ì‚¬ìš© ì‹œ)
```

### 5. ì¬í˜„ì„±ì´ ë³´ì¥ë˜ì§€ ì•ŠìŒ

```yaml
# 1. ì‹œë“œê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
environment:
  seed: 250104

# 2. num_workers í™•ì¸
experiment:
  num_workers: 0  # ì™„ì „í•œ ì¬í˜„ì„±ì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
  # ë˜ëŠ” num_workers > 0ì´ë©´ worker_init_fnì´ ìë™ ì ìš©ë¨
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™” íŒ

### 1. DataLoader ìµœì í™”

```yaml
experiment:
  batch_size: 16             # GPUì— ë§ê²Œ ìµœëŒ€í•œ í¬ê²Œ
  num_workers: 4             # CPU ì½”ì–´ ìˆ˜ (ë³´í†µ 4-8)
```

### 2. ëª¨ë¸ í¬ê¸° ì¡°ì •

```yaml
# í° GPU (V100, A100)
model:
  transformer_d_model: 512
  convlstm_hidden_channels: 128

# ì‘ì€ GPU (RTX 2080, 3070)
model:
  transformer_d_model: 256
  convlstm_hidden_channels: 64

# CPU only
model:
  transformer_d_model: 128
  convlstm_hidden_channels: 32
```

### 3. í˜¼í•© ì •ë°€ë„ í•™ìŠµ (AMP)

í˜„ì¬ ì½”ë“œì—ëŠ” í¬í•¨ë˜ì§€ ì•Šì•˜ì§€ë§Œ, í•„ìš”ì‹œ ì¶”ê°€ ê°€ëŠ¥:

```python
# trainers.pyì˜ Trainer.train_step()ì— ì¶”ê°€
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

with autocast():
    outputs = model(inputs, sdo)
    loss = criterion(outputs, targets)

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

## ğŸ”§ ê°œë°œ ê°€ì´ë“œ

### ìƒˆ Loss í•¨ìˆ˜ ì¶”ê°€ (ëª¨ë“ˆí™”ëœ êµ¬ì¡°)

```python
# losses/regression.py ë˜ëŠ” losses/advanced.pyì— ì¶”ê°€
class MyCustomLoss(nn.Module):
    def __init__(self, param1, param2):
        super().__init__()
        self.param1 = param1
        self.param2 = param2
    
    def forward(self, pred, target):
        # êµ¬í˜„
        loss = ...
        return loss

# losses/factory.pyì˜ create_loss() ìˆ˜ì •
loss_map = {
    'mse': nn.MSELoss,
    'my_custom': MyCustomLoss,  # ì¶”ê°€
    # ...
}
```

### ìƒˆ Metric ì¶”ê°€

```python
# trainers.pyì˜ MetricsTracker.reset() ìˆ˜ì •
def reset(self):
    self.metrics = {
        'loss': [],
        'mae': [],
        'my_metric': [],  # ì¶”ê°€
        # ...
    }

# Trainer.train_step()ì—ì„œ ê³„ì‚°
def train_step(self, data_dict):
    # ...
    my_metric = compute_my_metric(outputs, targets)
    
    return {
        'loss': total_loss.item(),
        'my_metric': my_metric,  # ì¶”ê°€
        # ...
    }
```

### ìƒˆ ë°ì´í„° ì¦ê°• ì¶”ê°€ (ëª¨ë“ˆí™”ëœ êµ¬ì¡°)

```python
# datasets/preprocessing.pyì˜ DataProcessor.apply_augmentation() ìˆ˜ì •
def apply_augmentation(self, input_array, sample_idx, file_name):
    rng = np.random.RandomState(seed)
    
    # ê¸°ì¡´ ì¦ê°•
    factors = np.array([0.8, 0.9, 1.0, 1.1, 1.2])
    augmented = input_array * rng.choice(factors, size=input_array.shape)
    
    # ìƒˆ ì¦ê°• ì¶”ê°€
    if rng.random() > 0.5:
        augmented = my_custom_augmentation(augmented, rng)
    
    return augmented
```

### ìƒˆ ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ ì¶”ê°€

```python
# models/my_component.py ìƒì„±
class MyComponent(nn.Module):
    def __init__(self, ...):
        super().__init__()
        # êµ¬í˜„
    
    def forward(self, x):
        # êµ¬í˜„
        return output

# models/__init__.pyì— ì¶”ê°€
from .my_component import MyComponent

__all__ = [
    # ...
    'MyComponent',
]
```

## ğŸ“Š ë°ì´í„° í¬ë§·

### HDF5 íŒŒì¼ êµ¬ì¡°

```
data_file.h5
â”œâ”€â”€ sdo_193              # SDO 193Ã… ì±„ë„ (T, H, W)
â”œâ”€â”€ sdo_211              # SDO 211Ã… ì±„ë„ (T, H, W)
â”œâ”€â”€ sdo_magnetogram      # SDO Magnetogram (T, H, W)
â”œâ”€â”€ omni_Bx_GSE_GSM_nT   # OMNI ë³€ìˆ˜ë“¤ (T,)
â”œâ”€â”€ omni_By_GSM_nT
â””â”€â”€ ...
```

### CSV íŒŒì¼ êµ¬ì¡°

```csv
file_name,class_day1,class_day2,...
sample_001.h5,0,1,...
sample_002.h5,1,1,...
```

## ğŸ¤ ê¸°ì—¬ ê°€ì´ë“œ

1. **ì½”ë“œ ìŠ¤íƒ€ì¼**: PEP 8 ì¤€ìˆ˜
2. **Docstring**: Google style docstring ì‚¬ìš©
3. **íƒ€ì… íŒíŠ¸**: ê°€ëŠ¥í•œ ëª¨ë“  í•¨ìˆ˜ì— íƒ€ì… íŒíŠ¸ ì¶”ê°€
4. **í…ŒìŠ¤íŠ¸**: ì£¼ìš” ê¸°ëŠ¥ì— ëŒ€í•œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License

## ğŸ‘¥ ì €ì

- Eunsu Park (KASI - Korea Astronomy and Space Science Institute)

## ğŸ“§ ë¬¸ì˜

 - eunsupark@kasi.re.kr (work)
 - phd.choux@gmail.com (home)

## ğŸ™ ê°ì‚¬ì˜ ê¸€

- SDO ë°ì´í„°: NASA Solar Dynamics Observatory
- OMNI ë°ì´í„°: NASA OMNIWeb

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

- ì—…ë°ì´íŠ¸ ì˜ˆì •