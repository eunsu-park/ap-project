# Enhanced Multi-Modal Model Configuration (v2)
# Updated for refactored codebase with pipeline_v2, train_v2, validation_v2

defaults:
  - _self_
  - override hydra/job_logging: none
  - override hydra/hydra_logging: none

hydra:
  output_subdir: null
  run:
    dir: .
  job:
    chdir: false

experiment:
  experiment_name: 'MULTITARGET_6_1-3_05'
  seed: 250104
  batch_size: 1
  enable_undersampling: true
  num_subsample: 6
  subsample_index: 5
  input_days:
   - 6
  target_days:
    - 1
    - 2
    - 3

environment:
  device: 'cuda'
  data_root: '/mmfs1/home/hl545/ap/renew/datasets'
  save_root: '/mmfs1/home/hl545/ap/renew/results'
  num_workers: 8

data:
  data_dir_name: 'oversampling_13'
  dataset_name: 'three_twelve_to_one'

  sdo_wavelengths:
    - 'aia_193'
    - 'aia_211'
    - 'hmi_magnetogram'
  sdo_image_size: 64
  sdo_start_index: 16
  sdo_end_index: 40

  input_variables:
      - 'bx_gse_gsm_nt'
      - 'by_gsm_nt'
      - 'bz_gsm_nt'
      - 'b_magnitude_of_avg_field_vector_nt'
      - 'plasma_flow_speed_km_s'
      - 'proton_density_n_cm3'
      - 'proton_temperature_k'
      - 'kp_index'
      - 'ap_index_nt'
      - 'dst_index_nt'
      - 'f10_7_index_sfu'
      - 'sunspot_number_r'
  input_start_index: 32
  input_end_index: 80

  target_variables:
    - 'ap_index_nt'
  target_start_index: 80
  target_end_index: 104

model:
  # Transformer configuration
  transformer_d_model: 256
  transformer_nhead: 8
  transformer_num_layers: 3
  transformer_dim_feedforward: 512
  transformer_dropout: 0.1

  # ConvLSTM configuration
  convlstm_input_channels: 3
  convlstm_hidden_channels: 64
  convlstm_kernel_size: 3
  convlstm_num_layers: 2

  # Cross-modal fusion configuration
  fusion_num_heads: 4
  fusion_dropout: 0.1

training:
  regression_loss_type: 'mse'
  contrastive_loss_type: 'consistency'  # 'consistency' or 'infonce'
  infonce_temperature: 0.3  # Only used if contrastive_type='infonce'
  lambda_contrastive: 0.1  # Weight for contrastive loss

  optimizer: 'adam'  # 'adam' or 'sgd'
  learning_rate: 0.0002

  num_epochs: 10
  report_freq: 100
  model_save_freq: 1

validation:
  checkpoint_path: '/home/hl545/ap/renew/results/MULTITARGET_6_1-3_05/checkpoint/model_epoch0020.pth'
  output_dir: '/home/hl545/ap/renew/results/MULTITARGET_6_1-3_05/saliency/epoch_0020'
  compute_alignment: true  # Whether to compute feature alignment (cosine similarity)
  save_plots: true  # Whether to save individual validation plots

mcd:
  checkpoint_path: '/home/hl545/ap/renew/results/MULTITARGET_6_1-3_05/checkpoint/model_epoch0020.pth'
  output_dir: '/home/hl545/ap/renew/results/MULTITARGET_6_1-3_05/mcd/epoch_0020'

# Attention-specific settings (optional)
attention:
  # Which layer to analyze primarily (-1 = last layer)
  target_layer: -1
  
  # Temporal importance calculation method
  importance_method: 'incoming'  # 'incoming' or 'outgoing'
  
  # Create visualizations
  create_plots: false  # Set to true for plots (slower)
  
  # Analysis options
  analyze_all_layers: true
  compute_statistics: true