# Enhanced Multi-Modal Model Configuration (v2)
# Updated for refactored codebase with pipeline_v2, train_v2, validation_v2

defaults:
  - _self_
  - override hydra/job_logging: none
  - override hydra/hydra_logging: none

hydra:
  output_subdir: null
  run:
    dir: .
  job:
    chdir: false

experiment:
  experiment_name: 'local'
  seed: 250104
  batch_size: 4
  enable_undersampling: true
  num_subsample: 14
  subsample_index: 0
  input_days:
   - 1
   - 2
   - 3
   - 4
   - 5
   - 6
   - 7
  target_days:
    - 1
    - 2
    - 3

environment:
  device: 'mps'
  data_root: '/opt/projects/10_Harim/01_AP/03_Dataset'
  save_root: '/opt/projects/10_Harim/01_AP/04_Result'
  num_workers: 8

data:
  data_dir_name: 'oversampling_13'
  dataset_name: 'three_twelve_to_one'

  sdo_wavelengths:
    - 'aia_193'
    - 'aia_211'
    - 'hmi_magnetogram'
  sdo_image_size: 64
  sdo_start_index: 12
  sdo_end_index: 40

  input_variables:
      - 'bx_gse_gsm_nt'
      - 'by_gsm_nt'
      - 'bz_gsm_nt'
      - 'b_magnitude_of_avg_field_vector_nt'
      - 'plasma_flow_speed_km_s'
      - 'proton_density_n_cm3'
      - 'proton_temperature_k'
      - 'kp_index'
      - 'ap_index_nt'
      - 'dst_index_nt'
      - 'f10_7_index_sfu'
      - 'sunspot_number_r'
  input_start_index: 24
  input_end_index: 80

  target_variables:
    - 'ap_index_nt'
  target_start_index: 80
  target_end_index: 104

model:
  # Transformer configuration
  transformer_d_model: 256
  transformer_nhead: 8
  transformer_num_layers: 3
  transformer_dim_feedforward: 512
  transformer_dropout: 0.1

  # ConvLSTM configuration
  convlstm_input_channels: 3
  convlstm_hidden_channels: 64
  convlstm_kernel_size: 3
  convlstm_num_layers: 2

  # Cross-modal fusion configuration
  fusion_num_heads: 4
  fusion_dropout: 0.1

training:
  regression_loss_type: 'mse'
  contrastive_loss_type: 'consistency'  # 'consistency' or 'infonce'
  infonce_temperature: 0.3  # Only used if contrastive_type='infonce'
  lambda_contrastive: 0.1  # Weight for contrastive loss

  optimizer: 'adam'  # 'adam' or 'sgd'
  learning_rate: 0.0002

  num_epochs: 10
  report_freq: 100
  model_save_freq: 1

validation:
  checkpoint_path: '/opt/projects/10_Harim/01_AP/04_Result/local_dev/checkpoint/model_epoch0010.pth'
  output_dir: '/opt/projects/10_Harim/01_AP/04_Result/local_dev/validation/epoch_0010'
  compute_alignment: true  # Whether to compute feature alignment (cosine similarity)
  save_plots: true  # Whether to save individual validation plots
