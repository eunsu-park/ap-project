# merge_data_improved.py ì‚¬ìš© ê°€ì´ë“œ

## ğŸ¯ ê°œì„  ì‚¬í•­ ìš”ì•½

### âœ… ì£¼ìš” ê°œì„ ì‚¬í•­

| í•­ëª© | Before | After |
|------|--------|-------|
| **DB ì—°ê²°** | ì „ì—­ ì—°ê²° (ë¶ˆì•ˆì •) | Context Manager (ì•ˆì „) |
| **ì—ëŸ¬ ì²˜ë¦¬** | `return False, None` | ìƒì„¸ ì—ëŸ¬ ë©”ì‹œì§€ + ë¡œê¹… |
| **ë³‘ë ¬ ì²˜ë¦¬** | âŒ ìˆœì°¨ ì²˜ë¦¬ | âœ… ë©€í‹°í”„ë¡œì„¸ì‹± |
| **ì¤‘ë³µ ë°©ì§€** | âŒ ì—†ìŒ | âœ… íŒŒì¼ ì²´í¬ + Progress íŒŒì¼ |
| **ì¬ì‹œë„** | âŒ ì—†ìŒ | âœ… 3íšŒ ì¬ì‹œë„ (ì„¤ì • ê°€ëŠ¥) |
| **ì§„í–‰ë¥ ** | âŒ ì—†ìŒ | âœ… tqdm ì§„í–‰ë°” |
| **ë¡œê¹…** | `print()` | logging ëª¨ë“ˆ (íŒŒì¼ + ì½˜ì†”) |
| **ë©”ëª¨ë¦¬** | ë¹„íš¨ìœ¨ì  | Pre-allocationìœ¼ë¡œ ê°œì„  |

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ê¸°ë³¸ ì‹¤í–‰

```bash
cd /Users/eunsupark/projects/ap
python merge_data_improved.py
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
============================================================
SDO + OMNI DATA MERGER
============================================================
DATASET CADENCE: 3 hours
SDO CADENCE: 6 hours
OMNI CADENCE: 3 hours
BEFORE 10 days to AFTER 5 days
SDO_NUM_SEQUENCE: 60
OMNI_NUM_SEQUENCE: 120
NUM_WORKERS: 7
============================================================
Total dates to process: 41,016
Already processed: 0
To process: 41,016

Starting parallel processing...
Processing dates: 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 18450/41016 [2:15:30<2:45:20, 2.27it/s]
```

### 2. ì¤‘ë‹¨ í›„ ì¬ì‹œì‘

í”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì–´ë„ **ìë™ìœ¼ë¡œ ì´ì–´ì„œ ì²˜ë¦¬**:

```bash
# Ctrl+Cë¡œ ì¤‘ë‹¨
^C
âš  Interrupted by user

# ë‹¤ì‹œ ì‹¤í–‰ â†’ ì²˜ë¦¬ëœ ë‚ ì§œëŠ” ìë™ ìŠ¤í‚µ
python merge_data_improved.py

Already processed: 18,450
To process: 22,566
```

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

### ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„ (41,016ê°œ ìƒ˜í”Œ)

| í•­ëª© | ê¸°ì¡´ (ìˆœì°¨) | ê°œì„  (ë³‘ë ¬ 8 cores) | ì†ë„ ê°œì„  |
|------|------------|-------------------|----------|
| **1ê°œ ì²˜ë¦¬ ì‹œê°„** | 2ì´ˆ | 2ì´ˆ | - |
| **ì „ì²´ ì‹œê°„** | 22.8ì‹œê°„ | 2.9ì‹œê°„ | **7.8ë°° ë¹ ë¦„** âš¡ |
| **ì¬ì‹œì‘ í›„** | ì²˜ìŒë¶€í„° | ì´ì–´ì„œ ì§„í–‰ | **ë¬´í•œëŒ€** âš¡ |

---

## ğŸ”§ ì„¤ì • ë³€ê²½

### config ì„¹ì…˜ ìˆ˜ì •

```python
# ì‹œê°„ ê°„ê²© ë³€ê²½
OMNI_CADENCE = 3  # OMNI ë°ì´í„° ê°„ê²© (hours)
SDO_CADENCE = 6   # SDO ë°ì´í„° ê°„ê²© (hours)
DATASET_CADENCE = 3  # ìƒ˜í”Œ ìƒì„± ê°„ê²© (hours)

# ì‹œí€€ìŠ¤ ê¸¸ì´ ë³€ê²½
BEFORE_DAY = 10  # ê³¼ê±° ë°ì´í„° (days)
AFTER_DAY = 5    # ë¯¸ë˜ ë°ì´í„° (days)

# ë³‘ë ¬ ì²˜ë¦¬
NUM_WORKERS = 4  # ì›Œì»¤ ìˆ˜ (ê¸°ë³¸: cpu_count() - 1)

# ì¬ì‹œë„
MAX_RETRIES = 3  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
RETRY_DELAY = 5  # ì¬ì‹œë„ ê°„ ëŒ€ê¸° ì‹œê°„ (seconds)
```

### ë‚ ì§œ ë²”ìœ„ ë³€ê²½

```python
# main() í•¨ìˆ˜ ë‚´
start_date = datetime.datetime(2015, 1, 1, 0, 0, 0)  # ì‹œì‘ ë‚ ì§œ
end_date = datetime.datetime(2020, 1, 1, 0, 0, 0)    # ì¢…ë£Œ ë‚ ì§œ
```

---

## ğŸ“ ìƒì„± íŒŒì¼

### 1. ë°ì´í„° íŒŒì¼

```
/Users/eunsupark/projects/ap/data/
â”œâ”€â”€ 2011010100/
â”‚   â”œâ”€â”€ aia_193.npy           # (60, H, W) - AIA 193Ã… ì‹œí€€ìŠ¤
â”‚   â”œâ”€â”€ aia_211.npy           # (60, H, W) - AIA 211Ã… ì‹œí€€ìŠ¤
â”‚   â”œâ”€â”€ hmi_magnetogram.npy   # (60, H, W) - HMI Magnetogram ì‹œí€€ìŠ¤
â”‚   â””â”€â”€ omni.csv              # (120 rows) - OMNI ì‹œê³„ì—´
â”œâ”€â”€ 2011010103/
â”‚   â”œâ”€â”€ ...
â””â”€â”€ ...
```

### 2. ë¡œê·¸ íŒŒì¼

**merge_data.log:**
```
2024-12-01 10:30:15 - INFO - [MainProcess] - Starting parallel processing...
2024-12-01 10:30:16 - INFO - [SpawnProcess-1] - Successfully processed: 2011-01-01 00:00:00
2024-12-01 10:30:17 - WARNING - [SpawnProcess-2] - Attempt 1/3 failed: No SDO data: aia_193 at 2011-02-15
2024-12-01 10:30:22 - INFO - [SpawnProcess-2] - Retrying in 5 seconds...
2024-12-01 10:30:27 - INFO - [SpawnProcess-2] - Successfully processed: 2011-02-15 00:00:00
```

### 3. Progress íŒŒì¼

**merge_progress.json:**
```json
{
  "processed": [
    "2011-01-01T00:00:00",
    "2011-01-01T03:00:00",
    "2011-01-01T06:00:00",
    ...
  ],
  "total": 18450,
  "last_updated": "2024-12-01T12:30:45"
}
```

---

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. DB ì—°ê²° ì—ëŸ¬

**ì¦ìƒ:**
```
ERROR - Connection failed: connection refused
```

**í•´ê²°:**
```bash
# PostgreSQL ì‹¤í–‰ í™•ì¸
pg_isready

# ì¬ì‹œì‘
brew services restart postgresql@14
```

### 2. ë©”ëª¨ë¦¬ ë¶€ì¡±

**ì¦ìƒ:**
í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ë˜ëŠ” ë§¤ìš° ëŠë ¤ì§

**í•´ê²°:**
```python
# merge_data_improved.py ìˆ˜ì •
NUM_WORKERS = 2  # ì›Œì»¤ ìˆ˜ ê°ì†Œ (8 â†’ 2)
```

### 3. ë””ìŠ¤í¬ ìš©ëŸ‰ ë¶€ì¡±

**ì¦ìƒ:**
```
ERROR - Save error: [Errno 28] No space left on device
```

**í™•ì¸:**
```bash
df -h /Users/eunsupark/projects/ap/data
```

**í•´ê²°:**
- ë¶ˆí•„ìš”í•œ íŒŒì¼ ì‚­ì œ
- ë‹¤ë¥¸ ë””ìŠ¤í¬ë¡œ SAVE_ROOT ë³€ê²½

### 4. íŠ¹ì • ë‚ ì§œ ê³„ì† ì‹¤íŒ¨

**ì¦ìƒ:**
```
ERROR - Failed after 3 retries: 2011-05-15: No SDO data
```

**ì›ì¸:**
- SDO ë°ì´í„° ëˆ„ë½
- OMNI ë°ì´í„° ëˆ„ë½
- íŒŒì¼ ì†ìƒ

**í™•ì¸:**
```python
# íŠ¹ì • ë‚ ì§œ ë””ë²„ê¹…
target_date = datetime.datetime(2011, 5, 15, 0, 0, 0)
success, error = process_single_date(target_date)
print(f"Success: {success}")
print(f"Error: {error}")
```

### 5. Progress íŒŒì¼ ì†ìƒ

**ì¦ìƒ:**
```
WARNING - Failed to load progress: ...
```

**í•´ê²°:**
```bash
# Progress íŒŒì¼ ì‚­ì œ í›„ ì¬ì‹œì‘
rm merge_progress.json
python merge_data_improved.py
```

---

## ğŸ’¡ ê³ ê¸‰ ì‚¬ìš©ë²•

### 1. íŠ¹ì • ì—°ë„ë§Œ ì²˜ë¦¬

```python
# main() í•¨ìˆ˜ ìˆ˜ì •
start_date = datetime.datetime(2020, 1, 1, 0, 0, 0)
end_date = datetime.datetime(2021, 1, 1, 0, 0, 0)
```

### 2. ì‹¤íŒ¨í•œ ë‚ ì§œë§Œ ì¬ì²˜ë¦¬

```python
# ë¡œê·¸ì—ì„œ ì‹¤íŒ¨í•œ ë‚ ì§œ ì¶”ì¶œ
failed_dates = [
    datetime.datetime(2011, 5, 15, 0, 0, 0),
    datetime.datetime(2012, 3, 20, 0, 0, 0),
]

# ë³‘ë ¬ ì²˜ë¦¬
with Pool(processes=NUM_WORKERS) as pool:
    results = pool.map(process_one_date_wrapper, failed_dates)
```

### 3. ë‹¨ì¼ ë‚ ì§œ í…ŒìŠ¤íŠ¸

```python
# ë³‘ë ¬ ì²˜ë¦¬ ì£¼ì„ ì²˜ë¦¬í•˜ê³ 
# ë‹¨ì¼ ë‚ ì§œë¡œ í…ŒìŠ¤íŠ¸
test_date = datetime.datetime(2011, 1, 1, 0, 0, 0)
result = process_one_date_wrapper(test_date)
print(result)
```

### 4. ì›Œì»¤ ìˆ˜ ë™ì  ì¡°ì •

```python
import psutil

# ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •
available_memory_gb = psutil.virtual_memory().available / (1024**3)

if available_memory_gb < 8:
    NUM_WORKERS = 2
elif available_memory_gb < 16:
    NUM_WORKERS = 4
else:
    NUM_WORKERS = cpu_count() - 1
```

### 5. ë¡œê¹… ë ˆë²¨ ë³€ê²½

```python
# ë” ìì„¸í•œ ë¡œê¹…
logging.basicConfig(
    level=logging.DEBUG,  # INFO â†’ DEBUG
    ...
)

# ëœ ìì„¸í•œ ë¡œê¹…
logging.basicConfig(
    level=logging.WARNING,  # INFO â†’ WARNING
    ...
)
```

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©

**í„°ë¯¸ë„ 1:**
```bash
python merge_data_improved.py
```

**í„°ë¯¸ë„ 2 (ì§„í–‰ë¥  í™•ì¸):**
```bash
# Progress íŒŒì¼ ëª¨ë‹ˆí„°ë§
watch -n 5 'cat merge_progress.json | jq ".total"'

# ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸
tail -f merge_data.log
```

**í„°ë¯¸ë„ 3 (ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰):**
```bash
# CPU/ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
top

# ë˜ëŠ”
htop
```

---

## ğŸ¯ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì‹¤í–‰ ì „
- [ ] PostgreSQL ì‹¤í–‰ ì¤‘
- [ ] SDO ë°ì´í„°ë² ì´ìŠ¤ ì ‘ê·¼ ê°€ëŠ¥
- [ ] OMNI ë°ì´í„°ë² ì´ìŠ¤ ì ‘ê·¼ ê°€ëŠ¥
- [ ] ì¶©ë¶„í•œ ë””ìŠ¤í¬ ìš©ëŸ‰ (ìµœì†Œ 100GB)
- [ ] ì¶©ë¶„í•œ ë©”ëª¨ë¦¬ (ìµœì†Œ 8GB)

### ì‹¤í–‰ ì¤‘
- [ ] ì§„í–‰ë¥  í‘œì‹œ ì •ìƒ
- [ ] ë¡œê·¸ íŒŒì¼ ìƒì„± í™•ì¸
- [ ] Progress íŒŒì¼ ì—…ë°ì´íŠ¸ í™•ì¸
- [ ] ì—ëŸ¬ ë°œìƒ ì‹œ ì¬ì‹œë„ í™•ì¸

### ì‹¤í–‰ í›„
- [ ] ì„±ê³µë¥  í™•ì¸ (> 95%)
- [ ] ì‹¤íŒ¨í•œ ë‚ ì§œ ì¬ì²˜ë¦¬
- [ ] ë°ì´í„° ìƒ˜í”Œë§ í™•ì¸
- [ ] íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦

---

## ğŸ”„ ê¸°ì¡´ ì½”ë“œì™€ ë¹„êµ

### í˜¸í™˜ì„±
- âœ… ë™ì¼í•œ ì¶œë ¥ í˜•ì‹
- âœ… ë™ì¼í•œ ë””ë ‰í† ë¦¬ êµ¬ì¡°
- âœ… ë™ì¼í•œ íŒŒì¼ëª…
- âœ… ê¸°ì¡´ ë°ì´í„°ì™€ í˜¸í™˜

### ì „í™˜ ë°©ë²•
```bash
# ê¸°ì¡´ ì½”ë“œ ë°±ì—…
cp merge_data.py merge_data_old.py

# ìƒˆ ì½”ë“œë¡œ êµì²´
cp merge_data_improved.py merge_data.py

# ì‹¤í–‰
python merge_data.py
```

---

## ğŸ“š ì½”ë“œ êµ¬ì¡°

```python
# ì„¤ì •
SAVE_ROOT = "..."
DB_CONFIGS = {...}
CADENCE = ...

# ë¡œê¹…
setup_logging()

# ìœ í‹¸ë¦¬í‹°
is_already_processed()
save_progress()
load_progress()
retry_on_failure()

# DB ì ‘ê·¼
get_sdo_data()
get_omni_data()

# ì´ë¯¸ì§€ ì²˜ë¦¬
read_png()
read_and_concatenate_images()

# ë©”ì¸ ì²˜ë¦¬
collect_sdo_files()
collect_omni_data()
save_merged_data()
process_single_date()

# ë³‘ë ¬ ì²˜ë¦¬
process_one_date_wrapper()
main()
```

---

## ğŸ“ í•™ìŠµ í¬ì¸íŠ¸

### 1. Context Manager íŒ¨í„´
```python
with PostgresManager(**config) as db:
    data = db.select(...)
# ìë™ìœ¼ë¡œ ì—°ê²° í•´ì œ
```

### 2. ì¬ì‹œë„ íŒ¨í„´
```python
def retry_on_failure(func, max_retries=3):
    for attempt in range(max_retries):
        try:
            return func()
        except:
            if attempt < max_retries - 1:
                sleep(delay)
            else:
                raise
```

### 3. ë³‘ë ¬ ì²˜ë¦¬ íŒ¨í„´
```python
with Pool(processes=num_workers) as pool:
    results = pool.map(process_func, items)
```

### 4. Progress ì €ì¥ íŒ¨í„´
```python
processed = load_progress()
to_process = [x for x in all if x not in processed]
# ì²˜ë¦¬...
save_progress(processed + newly_processed)
```

---

## ğŸ’¬ FAQ

**Q: ê¸°ì¡´ ì½”ë“œë³´ë‹¤ ëŠë¦° ê²ƒ ê°™ì•„ìš”**
A: ì²« ì‹¤í–‰ì€ progress ì²´í¬ë¡œ ì•½ê°„ ëŠë¦´ ìˆ˜ ìˆì§€ë§Œ, ì¬ì‹œì‘ ì‹œ í›¨ì”¬ ë¹ ë¦…ë‹ˆë‹¤.

**Q: ì¤‘ê°„ì— ë©ˆì·„ëŠ”ë° ë‹¤ì‹œ ì²˜ìŒë¶€í„° í•˜ë‚˜ìš”?**
A: ì•„ë‹ˆìš”! ìë™ìœ¼ë¡œ ì´ì–´ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

**Q: íŠ¹ì • ë‚ ì§œë§Œ ë‹¤ì‹œ ì²˜ë¦¬í•˜ê³  ì‹¶ì–´ìš”**
A: Progress íŒŒì¼ì—ì„œ í•´ë‹¹ ë‚ ì§œë§Œ ì œê±°í•˜ê±°ë‚˜, failed_dates ë¦¬ìŠ¤íŠ¸ë¡œ ì§ì ‘ ì‹¤í–‰í•˜ì„¸ìš”.

**Q: ë¡œê·¸ íŒŒì¼ì´ ë„ˆë¬´ ì»¤ì ¸ìš”**
A: ë¡œê·¸ ë¡œí…Œì´ì…˜ ì„¤ì •í•˜ê±°ë‚˜, ì£¼ê¸°ì ìœ¼ë¡œ ì‚­ì œí•˜ì„¸ìš”.

**Q: NUM_WORKERSë¥¼ ì–¼ë§ˆë¡œ ì„¤ì •í•´ì•¼ í•˜ë‚˜ìš”?**
A: `cpu_count() - 1`ì´ ê¸°ë³¸ê°’ì´ì§€ë§Œ, ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•˜ë©´ 2-4ë¡œ ì¤„ì´ì„¸ìš”.

---

**ì™„ë£Œ!** ğŸ‰

ë¬¸ì œ ìˆìœ¼ë©´ ì•Œë ¤ì£¼ì„¸ìš”! ğŸ˜Š